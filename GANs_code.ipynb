{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GANs_code.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iTIda_sY2cw1",
        "nQoslRppli7c",
        "j1pQUll8F8lJ",
        "Q5gnbkqNF_4I",
        "ibXzH1ZvFYU9",
        "Xf76c-O-6Nys",
        "OaWiY8v9m3AA",
        "HNLkRj_MYM45",
        "Z7_wq--7WUp1",
        "yClSDel92Ixv",
        "I_VeXe8wtQvK",
        "ZwrZrEH7FAeU",
        "H_QvdW5x7dAk",
        "PQJZp2xUWfav",
        "UH_0Mq4wqbQE",
        "AklX4WI-qbQG",
        "ItF_PFOIqbQH",
        "XnDFf0scqbQH",
        "oweTUPLD6j00",
        "-YPDwoD3y9vZ",
        "ljTKmzDUnh6Y",
        "4APyFVpnV-WP",
        "Fc8sxFo-jIht",
        "skeFQ1WCjIh3",
        "AuNesyukmepE",
        "SQmk1EhDmepG",
        "pXB14qkKiOjW",
        "NxrjPA_yiOjX",
        "2Veo1ixiiOjX",
        "JiF3OpF_H7tu",
        "uCAgzyciIaYT",
        "6AoADjVNyMcV",
        "uWUanMkHyMcc",
        "l_XCCAZFyMcd",
        "O9v_Szs9tFpl",
        "pmVjXwrQ2UQT",
        "3Dp4ClpAAnJv",
        "7Df0G4ZFAeoH",
        "rLghq0PDA2kS",
        "5mkx2QY5u-gf",
        "Wb_gXd3OOCSl"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQoslRppli7c"
      },
      "source": [
        "## **Imports**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1pQUll8F8lJ"
      },
      "source": [
        "### **pip installs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D192NIlyo8Jq",
        "outputId": "b6437465-67a5-44ed-d638-291840387fc6"
      },
      "source": [
        "!pip install -U albumentations\n",
        "import albumentations\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "!pip install torchgan\n",
        "import torchgan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n",
            "Collecting albumentations\n",
            "  Downloading albumentations-1.0.3-py3-none-any.whl (98 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▎                            | 10 kB 36.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 20 kB 33.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 40 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 51 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 71 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 81 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 92 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 98 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.16.2)\n",
            "Collecting opencv-python-headless>=4.1.1\n",
            "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.1 MB 90 kB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
            "Installing collected packages: opencv-python-headless, albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-1.0.3 opencv-python-headless-4.5.3.56\n",
            "Collecting torchgan\n",
            "  Downloading torchgan-0.0.5-py3-none-any.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from torchgan) (1.9.0+cu102)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from torchgan) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torchgan) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchgan) (1.19.5)\n",
            "Requirement already satisfied: torchvision>=0.4 in /usr/local/lib/python3.7/dist-packages (from torchgan) (0.10.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->torchgan) (3.7.4.3)\n",
            "Installing collected packages: torchgan\n",
            "Successfully installed torchgan-0.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vaWKhWJLpCe",
        "outputId": "8f297abe-14c7-4106-dc84-999760812dc7"
      },
      "source": [
        "!pip install pytorch-gan-metrics\n",
        "from pytorch_gan_metrics import (get_inception_score_from_directory)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-gan-metrics\n",
            "  Downloading pytorch_gan_metrics-0.3.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-gan-metrics) (1.9.0+cu102)\n",
            "Collecting scipy==1.5.4\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-gan-metrics) (4.62.2)\n",
            "Requirement already satisfied: torchvision>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-gan-metrics) (0.10.0+cu102)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from scipy==1.5.4->pytorch-gan-metrics) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->pytorch-gan-metrics) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.1->pytorch-gan-metrics) (7.1.2)\n",
            "Installing collected packages: scipy, pytorch-gan-metrics\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed pytorch-gan-metrics-0.3.2 scipy-1.5.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "scipy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5gnbkqNF_4I"
      },
      "source": [
        "### **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9d4J03Y6APa",
        "outputId": "fd5a0fd6-27f6-4782-9788-9a964cc4854c"
      },
      "source": [
        "import torch\n",
        "import json\n",
        "import skimage\n",
        "from skimage import io, exposure, img_as_uint, img_as_float\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from scipy import linalg\n",
        "import time\n",
        "from torchsummary import summary\n",
        "import random \n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from argparse import ArgumentParser\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import norm\n",
        "import pickle as pkl\n",
        "import os\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from torchvision.transforms.transforms import RandomHorizontalFlip, RandomVerticalFlip\n",
        "import torchvision.transforms as transforms\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision.utils import make_grid\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torch import Tensor\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.init as init\n",
        "import copy\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numbers\n",
        "import cv2\n",
        "from numpy import cov\n",
        "from numpy import trace\n",
        "from numpy import iscomplexobj\n",
        "from numpy import asarray\n",
        "from numpy.random import randint\n",
        "from scipy.linalg import sqrtm\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.datasets.mnist import load_data\n",
        "from skimage.transform import resize\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "from torch.autograd import Variable\n",
        "from torch import Tensor\n",
        "from torch.nn import Parameter\n",
        "\n",
        "\n",
        "# torch.autograd.set_detect_anomaly(False)\n",
        "# torch.autograd.profiler.profile(False)\n",
        "# torch.autograd.profiler.emit_nvtx(False)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibXzH1ZvFYU9"
      },
      "source": [
        "## **Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hiRYfCzT7xq"
      },
      "source": [
        "clean_imgs_path ='/content/drive/MyDrive/sim2real_dataset/sim2real_dataset/backgrounds'\n",
        "clean_imgs_list = os.listdir(clean_imgs_path)\n",
        "resize_shape = 512 \n",
        "crop_shape = 512\n",
        "\n",
        "class CleanDataset():\n",
        "    def __init__(self,real_dir,real_list, transform = None):\n",
        "\n",
        "        self.real_list = real_list\n",
        "        self.real_dir = real_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.real_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_path = os.path.join(self.real_dir, self.real_list[idx])\n",
        "        real = io.imread(real_path)\n",
        "        real = Image.fromarray(real)\n",
        "        if self.transform:\n",
        "          real = self.transform(real)\n",
        "        else:\n",
        "          real = transforms.ToTensor()(real)\n",
        "\n",
        "        return real\n",
        "\n",
        "class ElasticDataset():\n",
        "    def __init__(self,real_dir,real_list, transform = None):\n",
        "\n",
        "        self.real_list = real_list\n",
        "        self.real_dir = real_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.real_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_path = os.path.join(self.real_dir, self.real_list[idx])\n",
        "        real = cv2.imread(real_path)\n",
        "        real = cv2.cvtColor(real, cv2.COLOR_BGR2RGB)\n",
        "        real = albumentations.Resize(512,512)(image = real)[\"image\"]\n",
        "        real = albumentations.CenterCrop(512,512)(image = real)[\"image\"]\n",
        "        real = RandomElastic(alpha = 10,sigma = 0.1)(img = real)\n",
        "        real = transforms.ToTensor()(real)\n",
        "        # real = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])(real)\n",
        "        return real\n",
        "\n",
        "\n",
        "class FiveCropDataset():\n",
        "    def __init__(self,real_dir,real_list, transform = None):\n",
        "\n",
        "        self.real_list = real_list\n",
        "        self.real_dir = real_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.real_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_path = os.path.join(self.real_dir, self.real_list[idx])\n",
        "        real = Image.open(real_path)\n",
        "        real = real.crop((250, 100, 1700, 1050))\n",
        "        real = np.array(real.getdata()).reshape((950,1450,3))\n",
        "        if self.transform:\n",
        "          real = self.transform(real)\n",
        "          real = torch.stack(list(real), dim=0)\n",
        "        return real\n",
        "\n",
        "clean_transformation = transforms.Compose([\n",
        "   transforms.Resize(resize_shape),\n",
        "   transforms.CenterCrop(crop_shape),\n",
        "   transforms.ToTensor(),\n",
        "  #  transforms.Normalize(mean=(0,0,0),std=(1,1,1))\n",
        "])\n",
        "\n",
        "random_brightness = transforms.Compose([\n",
        "   transforms.Resize(resize_shape),\n",
        "   transforms.CenterCrop(crop_shape),\n",
        "   transforms.ColorJitter(brightness=0.2),\n",
        "   transforms.ToTensor()\n",
        "])\n",
        "\n",
        "random_flips = transforms.Compose([\n",
        "   transforms.Resize(resize_shape),\n",
        "   transforms.CenterCrop(crop_shape),\n",
        "   transforms.RandomHorizontalFlip(p=1),\n",
        "   transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "full_imgs_data = CleanDataset(clean_imgs_path,clean_imgs_list,transform = None)\n",
        "\n",
        "\n",
        "#Clean Dataset\n",
        "clean_imgs_data = CleanDataset(clean_imgs_path,clean_imgs_list,transform = clean_transformation)\n",
        "#Random Brightness Dataset\n",
        "brightness_imgs_data = CleanDataset(clean_imgs_path,clean_imgs_list,transform = random_brightness)\n",
        "#Random Flips Dataset\n",
        "flips_imgs_data = CleanDataset(clean_imgs_path,clean_imgs_list,transform = random_flips)\n",
        "#Elastic Deformation\n",
        "elastic_imgs_data = ElasticDataset(clean_imgs_path,clean_imgs_list,transform=None)\n",
        "\n",
        "#Concatenate Datasets and create DataLoader\n",
        "all_data = ConcatDataset([clean_imgs_data,flips_imgs_data,brightness_imgs_data,elastic_imgs_data])\n",
        "all_imgs_dataloader = DataLoader(all_data, batch_size=8, shuffle=True,num_workers=0)\n",
        "\n",
        "all_imgs_dataloader_batch_1 = DataLoader(all_data, batch_size=1, shuffle=True)\n",
        "# for i in range(40):\n",
        "#   plt.figure()\n",
        "#   plt.imshow(brightness_imgs_data[1].permute(1,2,0))\n",
        "#   plt.axis('off')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # plt.savefig('/content/drive/MyDrive/Thesis_Material/brightness_img.png', bbox_inches = 'tight')\n",
        "# plt.show()\n",
        "# plt.imshow(flips_imgs_data[1].permute(1,2,0))\n",
        "# plt.axis('off')\n",
        "# plt.savefig('/content/drive/MyDrive/Thesis_Material/flip_img.png',bbox_inches = 'tight')\n",
        "# plt.show()\n",
        "\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# im_rgb = cv2.cvtColor(clean_imgs_data[1].squeeze(0).permute(1,2,0).detach().cpu().numpy(), cv2.COLOR_BGR2RGB)\n",
        "# cv2_imshow(255*im_rgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf76c-O-6Nys"
      },
      "source": [
        "## **Useful Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCVLl6D96M0O"
      },
      "source": [
        "def show_images(image_tensor, num_images=8):\n",
        "    #image_tensor = image_tensor*0.5 + 0.5 \n",
        "    image_unflat = image_tensor.detach().cpu()\n",
        "    image_grid = make_grid(image_unflat, nrow=4,padding = 10, pad_value = 1)\n",
        "    plt.figure()\n",
        "    plt.imshow(image_grid.permute(1, 2, 0))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def check_or_create_dir(e,d):\n",
        "  if e == 0:\n",
        "    check_directory = os.path.isdir(d)\n",
        "    if check_directory == False:\n",
        "      os.makedirs(d)\n",
        "      print(\"created folder : \", d)\n",
        "    else:\n",
        "      print(d, \"folder already exists.\")\n",
        "\n",
        "\n",
        "def plot(loss,cur_epochs,gen_losses,disc_losses,dir):\n",
        "  if cur_epochs == 0:\n",
        "    pass\n",
        "  else:\n",
        "    if loss != 'wasserstein':\n",
        "      gen_losses = np.array(gen_losses)\n",
        "      disc_losses = np.array(disc_losses)\n",
        "\n",
        "      fig = plt.figure()\n",
        "      plt.plot(np.arange(len(gen_losses)),gen_losses,label = 'Gen Loss')\n",
        "      plt.plot(np.arange(len(disc_losses)),disc_losses,label='Disc Loss')\n",
        "      plt.title('Losses',fontsize = 15)\n",
        "      plt.xlabel('Epochs',fontsize = 10)\n",
        "      plt.ylabel('Loss', fontsize = 10)\n",
        "      plt.legend(prop={'size': 10})\n",
        "      plt.savefig(f\"{dir}/loss.png\")\n",
        "      plt.show()\n",
        "    else:\n",
        "      gen_losses = np.array(gen_losses)\n",
        "      fig = plt.figure()\n",
        "      plt.plot(np.arange(len(gen_losses)),gen_losses)\n",
        "      plt.title('Generator Loss',fontsize = 15)\n",
        "      plt.xlabel('Epochs',fontsize = 10)\n",
        "      plt.ylabel('Loss', fontsize = 10)\n",
        "      plt.savefig(f\"{dir}/gen_loss.png\")\n",
        "      plt.show()\n",
        "      disc_losses = np.array(disc_losses)\n",
        "      fig = plt.figure()\n",
        "      plt.plot(np.arange(len(disc_losses)),disc_losses)\n",
        "      plt.title('Discriminator Loss',fontsize = 15)\n",
        "      plt.xlabel('Epochs',fontsize = 10)\n",
        "      plt.ylabel('Loss', fontsize = 10)\n",
        "      plt.savefig(f\"{dir}/disc_loss.png\")\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def get_noise(n_samples, z_dim, device):\n",
        "    return torch.randn(n_samples,z_dim,device = device)\n",
        "\n",
        "def save_gen_images(dir,g_imgs_path, device, cur_epoch, z_dim, gen, num_images=8, size=(3, 512, 512)):\n",
        "\n",
        "  # if cur_epoch == 0:\n",
        "  check_directory = os.path.isdir(g_imgs_path)\n",
        "  if check_directory == False:\n",
        "    os.makedirs(g_imgs_path)\n",
        "    print(\"created folder : \", g_imgs_path)\n",
        "  else:\n",
        "    print(g_imgs_path, \"folder already exists.\")\n",
        "\n",
        "  gen.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    noise = get_noise(num_images,z_dim,device)\n",
        "    fakes = gen(noise)#[-1]\n",
        "    imgs = fakes.detach().cpu().view(-1,*size)\n",
        "    image_grid = make_grid(imgs, nrow=5,padding = 10, pad_value = 1)\n",
        "    fig = plt.figure(figsize=[50,50])\n",
        "    plt.imshow(image_grid.permute(1, 2, 0))\n",
        "    plt.axis('off')\n",
        "    plt.savefig(f\"{g_imgs_path}/gen_imgs_epoch{cur_epoch}.png\", bbox_inches = 'tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def init_weights(net, init_type='orthogonal', init_gain=0.02):\n",
        "    \"\"\"Initialize network weights.\n",
        "    Parameters:\n",
        "        net (network)   -- network to be initialized\n",
        "        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
        "        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n",
        "    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n",
        "    work better for some applications. Feel free to try yourself.\n",
        "    \"\"\"\n",
        "    def init_func(m):  # define the initialization function\n",
        "        classname = m.__class__.__name__ \n",
        "        if hasattr(m, 'weight') and classname.find('Conv') != -1:\n",
        "          if init_type == 'normal':\n",
        "              init.normal_(m.weight.data, 0.0, init_gain)\n",
        "          elif init_type == 'xavier':\n",
        "              init.xavier_normal_(m.weight.data, gain=init_gain)\n",
        "          elif init_type == 'kaiming':\n",
        "              init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "          elif init_type == 'orthogonal':\n",
        "              init.orthogonal_(m.weight.data, gain=init_gain)\n",
        "          else:\n",
        "              raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
        "          if hasattr(m, 'bias') and m.bias is not None:\n",
        "              init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
        "            init.normal_(m.weight.data, 1.0, init_gain)\n",
        "            init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    net.apply(init_func)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaWiY8v9m3AA"
      },
      "source": [
        "## **Current Device**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYHtB51Vm-b7"
      },
      "source": [
        "# !nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNLkRj_MYM45"
      },
      "source": [
        "## **GAN Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CegYxtw8Wk_B"
      },
      "source": [
        "class GAN(nn.Module):\n",
        "\n",
        "    def __init__(self, generator, discriminator):\n",
        "        super(GAN, self).__init__()\n",
        "        self.gen = generator\n",
        "        self.disc = discriminator\n",
        "        self.name = 'GAN'\n",
        "    \n",
        "    def get_gen(self):\n",
        "        return self.gen\n",
        "    \n",
        "    def get_disc(self):\n",
        "        return self.disc\n",
        "\n",
        "    def name(self):\n",
        "      return self.name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yClSDel92Ixv"
      },
      "source": [
        "## **FID (Fretchet Inception Distance)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQcI9dkL4QmO"
      },
      "source": [
        "def calculate_FID_score(real_path, fake_path):\n",
        "        \n",
        "    def load_images(path):\n",
        "        \n",
        "        images_list = os.listdir(path)\n",
        "        images_list.sort()\n",
        "        len_dataset = len(images_list)\n",
        "        dataset = np.zeros([len_dataset, 576, 576, 3])\n",
        "        for i in range(len_dataset):\n",
        "           # if i % 10 == 0:\n",
        "                #print(i)\n",
        "            dataset[i] = cv2.resize(cv2.imread(os.path.join(path, images_list[i])), (576, 576))\n",
        "        return dataset\n",
        "\n",
        " \n",
        "\n",
        "    # scale an array of images to a new size\n",
        "    def scale_images(images, new_shape):\n",
        "        images_list = list()\n",
        "        for image in images:\n",
        "            # resize with nearest neighbor interpolation\n",
        "            new_image = resize(image, new_shape, 0)\n",
        "            # store\n",
        "            images_list.append(new_image)\n",
        "        return asarray(images_list)\n",
        "    \n",
        "    # calculate frechet inception distance\n",
        "    def calculate_fid(model, images1, images2):\n",
        "        # calculate activations\n",
        "        act1 = model.predict(images1)\n",
        "        act2 = model.predict(images2)\n",
        "        # calculate mean and covariance statistics\n",
        "        mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
        "        mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
        "        # calculate sum squared difference between means\n",
        "        ssdiff = np.sum((mu1 - mu2)**2.0)\n",
        "        # calculate sqrt of product between cov\n",
        "        covmean = sqrtm(sigma1.dot(sigma2))\n",
        "        # check and correct imaginary numbers from sqrt\n",
        "        if iscomplexobj(covmean):\n",
        "            covmean = covmean.real\n",
        "        # calculate score\n",
        "        fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "        return fid\n",
        "\n",
        " \n",
        "\n",
        "    # prepare the inception v3 model\n",
        "    model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
        "    # define two fake collections of images\n",
        "    images1 = load_images(fake_path)\n",
        "    images2 = load_images(real_path)\n",
        "    #print('Prepared', images1.shape, images2.shape)\n",
        "    # convert integer to floating point values\n",
        "    images1 = images1.astype('float32')\n",
        "    images2 = images2.astype('float32')\n",
        "    # resize images\n",
        "    images1 = scale_images(images1, (299,299,3))\n",
        "    images2 = scale_images(images2, (299,299,3))\n",
        "    #print('Scaled', images1.shape, images2.shape)\n",
        "    # pre-process images\n",
        "    images1 = preprocess_input(images1)\n",
        "    images2 = preprocess_input(images2)\n",
        "\n",
        " \n",
        "\n",
        "    # fid between images1 and images2\n",
        "    fid = calculate_fid(model, images1, images2)\n",
        "    # print('FID (different): %.3f' % fid)\n",
        "    return fid\n",
        "\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_VeXe8wtQvK"
      },
      "source": [
        "## **Elastic Deformation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F23MAcm8rvn8"
      },
      "source": [
        "class RandomElastic(object):\n",
        "    \"\"\"Random Elastic transformation by CV2 method on image by alpha, sigma parameter.\n",
        "        # you can refer to:  https://blog.csdn.net/qq_27261889/article/details/80720359\n",
        "        # https://blog.csdn.net/maliang_1993/article/details/82020596\n",
        "        # https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.map_coordinates.html#scipy.ndimage.map_coordinates\n",
        "    Args:\n",
        "        alpha (float): alpha value for Elastic transformation, factor\n",
        "        if alpha is 0, output is original whatever the sigma;\n",
        "        if alpha is 1, output only depends on sigma parameter;\n",
        "        if alpha < 1 or > 1, it zoom in or out the sigma's Relevant dx, dy.\n",
        "        sigma (float): sigma value for Elastic transformation, should be \\ in (0.05,0.1)\n",
        "        mask (PIL Image) if not assign, set None.\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha, sigma):\n",
        "        assert isinstance(alpha, numbers.Number) and isinstance(sigma, numbers.Number), \\\n",
        "            \"alpha and sigma should be a single number.\"\n",
        "        assert 0.05 <= sigma <= 0.1, \\\n",
        "            \"In pathological image, sigma should be in (0.05,0.1)\"\n",
        "        self.alpha = alpha\n",
        "        self.sigma = sigma\n",
        "\n",
        "    @staticmethod\n",
        "    def RandomElasticCV2(img, alpha, sigma, mask=None):\n",
        "        alpha = img.shape[1] * alpha\n",
        "        sigma = img.shape[1] * sigma\n",
        "        if mask is not None:\n",
        "            mask = np.array(mask).astype(np.uint8)\n",
        "            img = np.concatenate((img, mask[..., None]), axis=2)\n",
        "\n",
        "        shape = img.shape\n",
        "\n",
        "        dx = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "        dy = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "        # dz = np.zeros_like(dx)\n",
        "\n",
        "        x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
        "        indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
        "\n",
        "        img = map_coordinates(img, indices, order=0, mode='reflect').reshape(shape)\n",
        "        if mask is not None:\n",
        "            return Image.fromarray(img[..., :3]), Image.fromarray(img[..., 3])\n",
        "        else:\n",
        "            #return Image.fromarray(img)\n",
        "            return img\n",
        "    def __call__(self, img, mask=None):\n",
        "        return self.RandomElasticCV2(np.array(img), self.alpha, self.sigma, mask)\n",
        "\n",
        "    def __repr__(self):\n",
        "        format_string = self.__class__.__name__ + '(alpha value={0})'.format(self.alpha)\n",
        "        format_string += ', sigma={0}'.format(self.sigma)\n",
        "        format_string += ')'\n",
        "        return format_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FulAkTE1rxps"
      },
      "source": [
        "# img = clean_imgs_data[17]\n",
        "# elastic_deformation = RandomElastic(alpha = 15,sigma = 0.1)\n",
        "# new_img = elastic_deformation(img.permute(1,2,0).numpy())\n",
        "# #print(new_img)\n",
        "# plt.imshow(new_img)\n",
        "# plt.show()\n",
        "# plt.imshow(img.permute(1,2,0).numpy())\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWSxg7wg2UNK"
      },
      "source": [
        "# img = cv2.imread(os.path.join(clean_imgs_path,'img_022.png'),cv2.IMREAD_COLOR)\n",
        "# cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "# def draw_grid(im, grid_size):\n",
        "#     # Draw grid lines\n",
        "#     for i in range(0, im.shape[1], grid_size):\n",
        "#         cv2.line(im, (i, 0), (i, im.shape[0]), \tcolor = (255,255,255), thickness = 2)\n",
        "#     for j in range(0, im.shape[0], grid_size):\n",
        "#         cv2.line(im, (0, j), (im.shape[1], j), \tcolor = (255,255,255), thickness = 2)\n",
        "\n",
        "# save_dir = '/content/drive/My Drive/Thesis_Material'\n",
        "# draw_grid(img, 150)\n",
        "# img_t = transforms.Compose([\n",
        "#    transforms.Resize(resize_shape),\n",
        "#    transforms.CenterCrop(crop_shape)])(Image.fromarray(img))\n",
        "# img_t = np.array(img_t)\n",
        "# cv2_imshow(img_t)\n",
        "# cv2.imwrite(os.path.join(save_dir,'example_with_grid_before.png'),img_t)\n",
        "# elastic_deformation = RandomElastic(alpha = 15,sigma = 0.1)\n",
        "# new_img = elastic_deformation(img_t)\n",
        "# cv2_imshow(new_img)\n",
        "# cv2.imwrite(os.path.join(save_dir,'example_with_grid_after.png'),new_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_QvdW5x7dAk"
      },
      "source": [
        "## **Self-Attention Block**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY7debaU7gjb"
      },
      "source": [
        "\n",
        "class Self_Attn(nn.Module):\n",
        "    \"\"\" Self attention Layer\"\"\"\n",
        "    def __init__(self,in_dim,activation):\n",
        "        super(Self_Attn,self).__init__()\n",
        "        self.chanel_in = in_dim\n",
        "        self.activation = activation\n",
        "        \n",
        "        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
        "        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
        "        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "        self.softmax  = nn.Softmax(dim=-1) #\n",
        "    def forward(self,x):\n",
        "        \"\"\"\n",
        "            inputs :\n",
        "                x : input feature maps( B X C X W X H)\n",
        "            returns :\n",
        "                out : self attention value + input feature \n",
        "                attention: B X N X N (N is Width*Height)\n",
        "        \"\"\"\n",
        "        m_batchsize,C,width ,height = x.size()\n",
        "        proj_query  = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1) # B X CX(N)\n",
        "        proj_key =  self.key_conv(x).view(m_batchsize,-1,width*height) # B X C x (*W*H)\n",
        "        energy =  torch.bmm(proj_query,proj_key) # transpose check\n",
        "        attention = self.softmax(energy) # BX (N) X (N) \n",
        "        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) # B X C X N\n",
        "\n",
        "        out = torch.bmm(proj_value,attention.permute(0,2,1) )\n",
        "        out = out.view(m_batchsize,C,width,height)\n",
        "        \n",
        "        out = self.gamma*out + x\n",
        "        return out,attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQJZp2xUWfav"
      },
      "source": [
        "## **IMD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeAVyhGQWhhY"
      },
      "source": [
        "import scipy.sparse as sps\n",
        "\n",
        "\n",
        "def _lanczos_m(A, m, nv, rademacher, SV=None):\n",
        "    '''\n",
        "    Lanczos algorithm computes symmetric m x m tridiagonal matrix T and matrix V with orthogonal rows\n",
        "        constituting the basis of the Krylov subspace K_m(A, x),\n",
        "        where x is an arbitrary starting unit vector.\n",
        "        This implementation parallelizes `nv` starting vectors.\n",
        "    \n",
        "    Arguments:\n",
        "        m: number of Lanczos steps\n",
        "        nv: number of random vectors\n",
        "        rademacher: True to use Rademacher distribution, \n",
        "                    False - standard normal for random vectors\n",
        "        SV: specified starting vectors\n",
        "    \n",
        "    Returns:\n",
        "        T: a nv x m x m tensor, T[i, :, :] is the ith symmetric tridiagonal matrix\n",
        "        V: a n x m x nv tensor, V[:, :, i] is the ith matrix with orthogonal rows \n",
        "    '''\n",
        "    orthtol = 1e-5\n",
        "    if type(SV) != np.ndarray:\n",
        "        if rademacher:\n",
        "            SV = np.sign(np.random.randn(A.shape[0], nv))\n",
        "        else:\n",
        "            SV = np.random.randn(A.shape[0], nv)  # init random vectors in columns: n x nv\n",
        "    V = np.zeros((SV.shape[0], m, nv))\n",
        "    T = np.zeros((nv, m, m))\n",
        "\n",
        "    np.divide(SV, np.linalg.norm(SV, axis=0), out=SV)  # normalize each column\n",
        "    V[:, 0, :] = SV\n",
        "\n",
        "    w = A.dot(SV)\n",
        "    alpha = np.einsum('ij,ij->j', w, SV)\n",
        "    w -= alpha[None, :] * SV\n",
        "    beta = np.einsum('ij,ij->j', w, w)\n",
        "    np.sqrt(beta, beta)\n",
        "\n",
        "    T[:, 0, 0] = alpha\n",
        "    T[:, 0, 1] = beta\n",
        "    T[:, 1, 0] = beta\n",
        "\n",
        "    np.divide(w, beta[None, :], out=w)\n",
        "    V[:, 1, :] = w\n",
        "    t = np.zeros((m, nv))\n",
        "\n",
        "    for i in range(1, m):\n",
        "        SVold = V[:, i - 1, :]\n",
        "        SV = V[:, i, :]\n",
        "\n",
        "        w = A.dot(SV)  # sparse @ dense\n",
        "        w -= beta[None, :] * SVold  # n x nv\n",
        "        np.einsum('ij,ij->j', w, SV, out=alpha)\n",
        "\n",
        "        T[:, i, i] = alpha\n",
        "\n",
        "        if i < m - 1:\n",
        "            w -= alpha[None, :] * SV  # n x nv\n",
        "            # reortho\n",
        "            np.einsum('ijk,ik->jk', V, w, out=t)\n",
        "            w -= np.einsum('ijk,jk->ik', V, t)\n",
        "            np.einsum('ij,ij->j', w, w, out=beta)\n",
        "            np.sqrt(beta, beta)\n",
        "            np.divide(w, beta[None, :], out=w)\n",
        "\n",
        "            T[:, i, i + 1] = beta\n",
        "            T[:, i + 1, i] = beta\n",
        "\n",
        "            # more reotho\n",
        "            innerprod = np.einsum('ijk,ik->jk', V, w)\n",
        "            reortho = False\n",
        "            for _ in range(100):\n",
        "                if not (innerprod > orthtol).sum():\n",
        "                    reortho = True\n",
        "                    break\n",
        "                np.einsum('ijk,ik->jk', V, w, out=t)\n",
        "                w -= np.einsum('ijk,jk->ik', V, t)\n",
        "                np.divide(w, np.linalg.norm(w, axis=0)[None, :], out=w)\n",
        "                innerprod = np.einsum('ijk,ik->jk', V, w)\n",
        "\n",
        "            V[:, i + 1, :] = w\n",
        "\n",
        "            if (np.abs(beta) > 1e-6).sum() == 0 or not reortho:\n",
        "                break\n",
        "    return T, V\n",
        "\n",
        "\n",
        "def _slq(A, m, niters, rademacher):\n",
        "    '''\n",
        "    Compute the trace of matrix exponential\n",
        "    \n",
        "    Arguments:\n",
        "        A: square matrix in trace(exp(A))\n",
        "        m: number of Lanczos steps\n",
        "        niters: number of quadratures (also, the number of random vectors in the hutchinson trace estimator)\n",
        "        rademacher: True to use Rademacher distribution, False - standard normal for random vectors in Hutchinson\n",
        "    Returns:\n",
        "        trace: estimate of trace of matrix exponential\n",
        "    '''\n",
        "    T, _ = _lanczos_m(A, m, niters, rademacher)\n",
        "    eigvals, eigvecs = np.linalg.eigh(T)\n",
        "    expeig = np.exp(eigvals)\n",
        "    sqeigv1 = np.power(eigvecs[:, 0, :], 2)\n",
        "    trace = A.shape[-1] * (expeig * sqeigv1).sum() / niters\n",
        "    return trace\n",
        "\n",
        "\n",
        "def _slq_ts(A, m, niters, ts, rademacher):\n",
        "    '''\n",
        "    Compute the trace of matrix exponential\n",
        "    \n",
        "    Arguments:\n",
        "        A: square matrix in trace(exp(-t*A)), where t is temperature\n",
        "        m: number of Lanczos steps\n",
        "        niters: number of quadratures (also, the number of random vectors in the hutchinson trace estimator)\n",
        "        ts: an array with temperatures\n",
        "        rademacher: True to use Rademacher distribution, False - standard normal for random vectors in Hutchinson\n",
        "    Returns:\n",
        "        trace: estimate of trace of matrix exponential across temperatures `ts`\n",
        "    '''\n",
        "    T, _ = _lanczos_m(A, m, niters, rademacher)\n",
        "    eigvals, eigvecs = np.linalg.eigh(T)\n",
        "    expeig = np.exp(-np.outer(ts, eigvals)).reshape(ts.shape[0], niters, m)\n",
        "    sqeigv1 = np.power(eigvecs[:, 0, :], 2)\n",
        "    traces = A.shape[-1] * (expeig * sqeigv1).sum(-1).mean(-1)\n",
        "    return traces\n",
        "\n",
        "\n",
        "def _slq_ts_fs(A, m, niters, ts, rademacher, fs):\n",
        "    '''\n",
        "    Compute the trace of matrix functions\n",
        "    \n",
        "    Arguments:\n",
        "        A: square matrix in trace(exp(-t*A)), where t is temperature\n",
        "        m: number of Lanczos steps\n",
        "        niters: number of quadratures (also, the number of random vectors in the hutchinson trace estimator)\n",
        "        ts: an array with temperatures\n",
        "        rademacher: True to use Rademacher distribution, else - standard normal for random vectors in Hutchinson\n",
        "        fs: a list of functions\n",
        "    Returns:\n",
        "        traces: estimate of traces for each of the functions in fs\n",
        "    '''\n",
        "    T, _ = _lanczos_m(A, m, niters, rademacher)\n",
        "    eigvals, eigvecs = np.linalg.eigh(T)\n",
        "    traces = np.zeros((len(fs), len(ts)))\n",
        "    for i, f in enumerate(fs):\n",
        "        expeig = f(-np.outer(ts, eigvals)).reshape(ts.shape[0], niters, m)\n",
        "        sqeigv1 = np.power(eigvecs[:, 0, :], 2)\n",
        "        traces[i, :] = A.shape[-1] * (expeig * sqeigv1).sum(-1).mean(-1)\n",
        "    return traces\n",
        "\n",
        "\n",
        "def slq_red_var(A, m, niters, ts, rademacher):\n",
        "    '''\n",
        "    Compute the trace of matrix exponential with reduced variance\n",
        "    \n",
        "    Arguments:\n",
        "        A: square matrix in trace(exp(-t*A)), where t is temperature\n",
        "        m: number of Lanczos steps\n",
        "        niters: number of quadratures (also, the number of random vectors in the hutchinson trace estimator)\n",
        "        ts: an array with temperatures\n",
        "    Returns:\n",
        "        traces: estimate of trace for each temperature value in `ts`\n",
        "    '''\n",
        "    fs = [np.exp, lambda x: x]\n",
        "\n",
        "    traces = _slq_ts_fs(A, m, niters, ts, rademacher, fs)\n",
        "    subee = traces[0, :] - traces[1, :] / np.exp(ts)\n",
        "    sub = - ts * A.shape[0] / np.exp(ts)\n",
        "    return subee + sub\n",
        "\n",
        "\n",
        "from scipy.sparse import lil_matrix, diags, eye\n",
        "\n",
        "\n",
        "def np_euc_cdist(data):\n",
        "    dd = np.sum(data*data, axis=1)\n",
        "    dist = -2*np.dot(data, data.T)\n",
        "    dist += dd + dd[:, np.newaxis] \n",
        "    np.fill_diagonal(dist, 0)\n",
        "    np.sqrt(dist, dist)\n",
        "    return dist\n",
        "\n",
        "\n",
        "def construct_graph_sparse(data, k):\n",
        "    n = len(data)\n",
        "    spmat = lil_matrix((n, n))\n",
        "    dd = np.sum(data*data, axis=1)\n",
        "    \n",
        "    for i in range(n):\n",
        "        dists = dd - 2*data[i, :].dot(data.T)\n",
        "        inds = np.argpartition(dists, k+1)[:k+1]\n",
        "        inds = inds[inds!=i]\n",
        "        spmat[i, inds] = 1\n",
        "            \n",
        "    return spmat.tocsr()\n",
        "\n",
        "\n",
        "def construct_graph_kgraph(data, k):\n",
        "    import pykgraph\n",
        "\n",
        "    n = len(data)\n",
        "    spmat = lil_matrix((n, n))\n",
        "    index = pykgraph.KGraph(data, 'euclidean')\n",
        "    index.build(reverse=0, K=2 * k + 1, L=2 * k + 50)\n",
        "    result = index.search(data, K=k + 1)[:, 1:]\n",
        "    spmat[np.repeat(np.arange(n), k, 0), result.ravel()] = 1\n",
        "    return spmat.tocsr()\n",
        "\n",
        "\n",
        "def _laplacian_sparse(A, normalized=True):\n",
        "    D = A.sum(1).A1\n",
        "    if normalized:\n",
        "        Dsqrt = diags(1/np.sqrt(D))\n",
        "        L = eye(A.shape[0]) - Dsqrt.dot(A).dot(Dsqrt)\n",
        "    else:\n",
        "        L = diags(D) - A\n",
        "    return L\n",
        "\n",
        "import scipy.sparse as sps\n",
        "\n",
        "EPSILON = 1e-6\n",
        "NORMALIZATION = 1e6\n",
        "\n",
        "\n",
        "def _build_graph(data, k=5, graph_builder='sparse', normalized=True):\n",
        "    \"\"\"\n",
        "    Return Laplacian from data or load preconstructed from path\n",
        "    Arguments:\n",
        "        data: samples\n",
        "        k: number of neighbours for graph construction\n",
        "        graph_builder: if 'kgraph', use faster graph construction\n",
        "        normalized: if True, use nnormalized Laplacian\n",
        "    Returns:\n",
        "        L: Laplacian of the graph constructed with data\n",
        "    \"\"\"\n",
        "    if graph_builder == 'sparse':\n",
        "        A = construct_graph_sparse(data, k)\n",
        "    elif graph_builder == 'kgraph':\n",
        "        A = construct_graph_kgraph(data, k)\n",
        "    else:\n",
        "        raise Exception('Please specify graph builder: sparse or kgraph.')\n",
        "    A = (A + A.T) / 2\n",
        "    A.data = np.ones(A.data.shape)\n",
        "    L = _laplacian_sparse(A, normalized)\n",
        "    return L\n",
        "\n",
        "\n",
        "def _normalize_msid(msid, normalization, n, k, ts):\n",
        "    normed_msid = msid.copy()\n",
        "    if normalization == 'empty':\n",
        "        normed_msid /= n\n",
        "    elif normalization == 'complete':\n",
        "        normed_msid /= (1 + (n - 1) * np.exp(-(1 + 1 / (n - 1)) * ts))\n",
        "    elif normalization == 'er':\n",
        "        xs = np.linspace(0, 1, n)\n",
        "        er_spectrum = 4 / np.sqrt(k) * xs + 1 - 2 / np.sqrt(k)\n",
        "        er_msid = np.exp(-np.outer(ts, er_spectrum)).sum(-1)\n",
        "        normed_msid = normed_msid / (er_msid + EPSILON)\n",
        "    elif normalization == 'none' or normalization is None:\n",
        "        pass\n",
        "    else:\n",
        "        raise ValueError('Unknown normalization parameter!')\n",
        "    return normed_msid\n",
        "\n",
        "\n",
        "def msid_score(x, y, ts=np.logspace(-1, 1, 256), k=5, m=10, niters=100, rademacher=False, graph_builder='sparse',\n",
        "              msid_mode='max', normalized_laplacian=True, normalize='empty'):\n",
        "    '''\n",
        "    Compute the msid score between two samples, x and y\n",
        "    Arguments:\n",
        "        x: x samples\n",
        "        y: y samples\n",
        "        ts: temperature values\n",
        "        k: number of neighbours for graph construction\n",
        "        m: Lanczos steps in SLQ\n",
        "        niters: number of starting random vectors for SLQ\n",
        "        rademacher: if True, sample random vectors from Rademacher distributions, else sample standard normal distribution\n",
        "        graph_builder: if 'kgraph', uses faster graph construction (options: 'sparse', 'kgraph')\n",
        "        msid_mode: 'l2' to compute the l2 norm of the distance between `msid1` and `msid2`;\n",
        "                'max' to find the maximum abosulute difference between two descriptors over temperature\n",
        "        normalized_laplacian: if True, use normalized Laplacian\n",
        "        normalize: 'empty' for average heat kernel (corresponds to the empty graph normalization of NetLSD),\n",
        "                'complete' for the complete, 'er' for erdos-renyi\n",
        "                normalization, 'none' for no normalization\n",
        "    Returns:\n",
        "        msid_score: the scalar value of the distance between discriptors\n",
        "    '''\n",
        "    normed_msidx = msid_descriptor(x, ts, k, m, niters, rademacher, graph_builder, normalized_laplacian, normalize)\n",
        "    normed_msidy = msid_descriptor(y, ts, k, m, niters, rademacher, graph_builder, normalized_laplacian, normalize)\n",
        "\n",
        "    c = np.exp(-2 * (ts + 1 / ts))\n",
        "\n",
        "    if msid_mode == 'l2':\n",
        "        score = np.linalg.norm(normed_msidx - normed_msidy)\n",
        "    elif msid_mode == 'max':\n",
        "        score = np.amax(c * np.abs(normed_msidx - normed_msidy))\n",
        "    else:\n",
        "        raise Exception('Use either l2 or max mode.')\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "def msid_descriptor(x, ts=np.logspace(-1, 1, 256), k=5, m=10, niters=100, rademacher=False, graph_builder='sparse',\n",
        "              normalized_laplacian=True, normalize='empty'):\n",
        "    '''\n",
        "    Compute the msid descriptor for a single sample x\n",
        "    Arguments:\n",
        "        x: x samples\n",
        "        ts: temperature values\n",
        "        k: number of neighbours for graph construction\n",
        "        m: Lanczos steps in SLQ\n",
        "        niters: number of starting random vectors for SLQ\n",
        "        rademacher: if True, sample random vectors from Rademacher distributions, else sample standard normal distribution\n",
        "        graph_builder: if 'kgraph', uses faster graph construction (options: 'sparse', 'kgraph')\n",
        "        normalized_laplacian: if True, use normalized Laplacian\n",
        "        normalize: 'empty' for average heat kernel (corresponds to the empty graph normalization of NetLSD),\n",
        "                'complete' for the complete, 'er' for erdos-renyi\n",
        "                normalization, 'none' for no normalization\n",
        "    Returns:\n",
        "        normed_msidx: normalized msid descriptor\n",
        "    '''\n",
        "    Lx = _build_graph(x, k, graph_builder, normalized_laplacian)\n",
        "\n",
        "    nx = Lx.shape[0]\n",
        "    msidx = slq_red_var(Lx, m, niters, ts, rademacher)\n",
        "\n",
        "    normed_msidx = _normalize_msid(msidx, normalize, nx, k, ts) * NORMALIZATION\n",
        "\n",
        "    return normed_msidx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AklX4WI-qbQG"
      },
      "source": [
        "# **DC Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJEUovshqbQH"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz, ngf = 16, nc = 3):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.nc = nc\n",
        "        self.nz = nz\n",
        "        self.ngf = ngf\n",
        "\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "\n",
        "        self.deconv1 = nn.ConvTranspose2d(self.nz, self.ngf * 16, 4, 2, 1)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(self.ngf*16)\n",
        "        self.deconv2 = nn.ConvTranspose2d(self.ngf * 16,  self.ngf * 8, 4, 2, 1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(self.ngf*8)\n",
        "        self.deconv3 = nn.ConvTranspose2d(self.ngf * 8,  self.ngf * 8, 4, 2, 1)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(self.ngf*8)\n",
        "        self.deconv4 = nn.ConvTranspose2d(self.ngf * 8,  self.ngf * 8, 4, 2, 1)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(self.ngf*8)\n",
        "        self.deconv5 = nn.ConvTranspose2d(self.ngf * 8,  self.ngf * 4, 4, 2, 1)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv6 = nn.ConvTranspose2d(self.ngf * 4,  self.ngf * 4, 4, 2, 1)\n",
        "        self.batchnorm6 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv7 = nn.ConvTranspose2d(self.ngf * 4,  self.ngf * 4, 4, 2, 1)\n",
        "        self.batchnorm7 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv8 = nn.ConvTranspose2d(self.ngf * 4,  self.ngf * 4, 4, 2, 1)\n",
        "        self.batchnorm8 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv9 = nn.ConvTranspose2d(self.ngf * 4,  self.nc,   4, 2, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        input = input.view(len(input), self.nz, 1, 1)\n",
        "\n",
        "        output = self.deconv1(input)\n",
        "        output = self.batchnorm1(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv2(output)\n",
        "        output = self.batchnorm2(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv3(output)\n",
        "        output = self.batchnorm3(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv4(output)\n",
        "        output = self.batchnorm4(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv5(output)\n",
        "        output = self.batchnorm5(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv6(output)\n",
        "        output = self.batchnorm6(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "\n",
        "        output = self.deconv7(output)\n",
        "        output = self.batchnorm7(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv8(output)\n",
        "        output = self.batchnorm8(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv9(output)\n",
        "        output = self.tanh(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def get_name(self):\n",
        "      return 'DC Generator'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnDFf0scqbQH"
      },
      "source": [
        "# **DC Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4y-Kt5yqbQH"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self, d=64):\n",
        "\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, d, 4, 2, 1)\n",
        "        self.conv1_in = nn.BatchNorm2d(d)\n",
        "        self.conv2 = nn.Conv2d(d, d * 2, 4, 2, 1)\n",
        "        self.conv2_in = nn.BatchNorm2d(d * 2)\n",
        "        self.conv3 = nn.Conv2d(d * 2, d * 4, 4, 2, 1)\n",
        "        self.conv3_in = nn.BatchNorm2d(d * 4)\n",
        "        self.conv4 = nn.Conv2d(d * 4, d * 8, 4, 2, 1)\n",
        "        self.conv4_in = nn.BatchNorm2d(d * 8)\n",
        "        self.conv5 = nn.Conv2d(d * 8, 1, 3, 1, 1)\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    # forward method\n",
        "    def forward(self, input):\n",
        "        x = input\n",
        "        x = self.leaky(self.conv1(x))\n",
        "        x = self.leaky(self.conv2_in(self.conv2(x)))\n",
        "        x = self.leaky(self.conv3_in(self.conv3(x)))\n",
        "        x = self.leaky(self.conv4_in(self.conv4(x)))\n",
        "        x = self.conv5(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "        \n",
        "    def get_name(self):\n",
        "      return 'DC Discriminator'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljTKmzDUnh6Y"
      },
      "source": [
        "# **Discriminator with Spectral Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXRhjWOrnlD8"
      },
      "source": [
        "class SNDiscriminator(nn.Module):\n",
        "    def __init__(self,d = 64):\n",
        "        super(SNDiscriminator,self).__init__()\n",
        "\n",
        "        self.conv2d_1 = spectral_norm(nn.Conv2d(3,d,4,2,1))\n",
        "        self.conv2d_2 = spectral_norm(nn.Conv2d(d,d*2, 4,2,1))\n",
        "        self.batchnorm2 = nn.BatchNorm2d(d*2)\n",
        "        self.conv2d_3 = spectral_norm(nn.Conv2d(d*2,d*4, 4,2,1))\n",
        "        self.batchnorm3 = nn.BatchNorm2d(d*4)\n",
        "        self.conv2d_4 = spectral_norm(nn.Conv2d(d*4,d*8, 4,2,1))\n",
        "        self.batchnorm4 = nn.BatchNorm2d(d*8)\n",
        "        self.conv2d_5 = spectral_norm(nn.Conv2d(d*8,d*8,4,2,1))\n",
        "        self.batchnorm5 = nn.BatchNorm2d(d*8)\n",
        "        self.conv2d_6 = spectral_norm(nn.Conv2d(d*8,1,3,1,1))\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "    def forward(self, x):\n",
        "      \n",
        "        x = self.leaky(self.conv2d_1(x))\n",
        "        x = self.leaky(self.batchnorm2(self.conv2d_2(x)))\n",
        "        x = self.leaky(self.batchnorm3(self.conv2d_3(x)))\n",
        "        x = self.leaky(self.batchnorm4(self.conv2d_4(x)))\n",
        "        x = self.leaky(self.batchnorm5(self.conv2d_5(x)))\n",
        "        x = self.sigmoid(self.conv2d_6(x))\n",
        "\n",
        "        return x\n",
        "    def get_name(self):\n",
        "      return 'Spectral Normalization Discriminator'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc8sxFo-jIht"
      },
      "source": [
        "# **Self Attention Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpixqFoyjIh2"
      },
      "source": [
        "class SAGenerator(nn.Module):\n",
        "    def __init__(self, nz, ngf =16, nc = 3):\n",
        "        super(SAGenerator, self).__init__()\n",
        "\n",
        "        self.nc = nc\n",
        "        self.nz = nz\n",
        "        self.ngf = ngf\n",
        "\n",
        "        self.attn1 = Self_Attn(ngf*4,'leakyrelu')\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "        \n",
        "        self.deconv1 = (nn.ConvTranspose2d(self.nz, self.ngf * 16, 4, 2, 1))\n",
        "        self.batchnorm1 = nn.BatchNorm2d(self.ngf*16)\n",
        "        self.deconv2 = (nn.ConvTranspose2d(self.ngf * 16,  self.ngf * 8, 4, 2, 1))\n",
        "        self.batchnorm2 = nn.BatchNorm2d(self.ngf*8)\n",
        "        self.deconv3 = (nn.ConvTranspose2d(self.ngf * 8,  self.ngf * 8, 4, 2, 1))\n",
        "        self.batchnorm3 = nn.BatchNorm2d(self.ngf*8)\n",
        "        self.deconv4 = (nn.ConvTranspose2d(self.ngf * 8,  self.ngf * 8, 4, 2, 1))\n",
        "        self.batchnorm4 = nn.BatchNorm2d(self.ngf*8)\n",
        "        self.deconv5 = (nn.ConvTranspose2d(self.ngf * 8,  self.ngf * 4, 4, 2, 1))\n",
        "        self.batchnorm5 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv6 = (nn.ConvTranspose2d(self.ngf * 4,  self.ngf * 4, 4, 2, 1))\n",
        "        self.batchnorm6 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv7 = (nn.ConvTranspose2d(self.ngf * 4,  self.ngf * 4, 4, 2, 1))\n",
        "        self.batchnorm7 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv8 = (nn.ConvTranspose2d(self.ngf * 4,  self.ngf * 4, 4, 2, 1))\n",
        "        self.batchnorm8 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv9 = (nn.ConvTranspose2d(self.ngf * 4,  self.nc,   4, 2, 1))\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        input = input.view(len(input), self.nz, 1, 1)\n",
        "\n",
        "        output = self.deconv1(input)\n",
        "        output = self.batchnorm1(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv2(output)\n",
        "        output = self.batchnorm2(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv3(output)\n",
        "        output = self.batchnorm3(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv4(output)\n",
        "        output = self.batchnorm4(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "\n",
        "        output = self.deconv5(output)\n",
        "        output = self.batchnorm5(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv6(output)\n",
        "        output = self.batchnorm6(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output,_ = self.attn1(output)\n",
        "\n",
        "        output = self.deconv7(output)\n",
        "        output = self.batchnorm7(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "\n",
        "        output = self.deconv8(output)\n",
        "        output = self.batchnorm8(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "\n",
        "        output = self.deconv9(output)\n",
        "        output = self.tanh(output)\n",
        "\n",
        "        return output\n",
        "    \n",
        "    def get_name(self):\n",
        "      return 'Self Attention Generator with Spectral Normalization'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQmk1EhDmepG"
      },
      "source": [
        "# **Critic with Spectral Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8ZMpSdDmepG"
      },
      "source": [
        "class SpectralCritic(nn.Module):\n",
        "    def __init__(self,d = 64):\n",
        "        super(SpectralCritic,self).__init__()\n",
        "\n",
        "        self.conv2d_1 = spectral_norm(nn.Conv2d(3,d,4,2,1))\n",
        "        self.conv2d_2 = spectral_norm(nn.Conv2d(d,d*2, 4,2,1))\n",
        "        self.batchnorm2 = nn.BatchNorm2d(d*2)\n",
        "        self.conv2d_3 = spectral_norm(nn.Conv2d(d*2,d*4, 4,2,1))\n",
        "        self.batchnorm3 = nn.BatchNorm2d(d*4)\n",
        "        self.conv2d_4 = spectral_norm(nn.Conv2d(d*4,d*8, 4,2,1))\n",
        "        self.batchnorm4 = nn.BatchNorm2d(d*8)\n",
        "        self.conv2d_5 = spectral_norm(nn.Conv2d(d*8,d*8,4,2,1))\n",
        "        self.batchnorm5 = nn.BatchNorm2d(d*8)\n",
        "        self.conv2d_6 = spectral_norm(nn.Conv2d(d*8,1,3,1,1))\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "    def forward(self, x):\n",
        "      \n",
        "        x = self.leaky(self.conv2d_1(x))\n",
        "        x = self.leaky(self.batchnorm2(self.conv2d_2(x)))\n",
        "        x = self.leaky(self.batchnorm3(self.conv2d_3(x)))\n",
        "        x = self.leaky(self.batchnorm4(self.conv2d_4(x)))\n",
        "        x = self.leaky(self.batchnorm5(self.conv2d_5(x)))\n",
        "        x = self.conv2d_6(x)\n",
        "\n",
        "        return x\n",
        "    def get_name(self):\n",
        "      return 'Spectral Normalization Critic'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Veo1ixiiOjX"
      },
      "source": [
        "# **Critic**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xkTgtTQiOjX"
      },
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self,d = 64):\n",
        "        super(Critic,self).__init__()\n",
        "\n",
        "        self.conv2d_1 = nn.Conv2d(3,d,4,2,1)\n",
        "        self.conv2d_2 = nn.Conv2d(d,d*2, 4,2,1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(d*2)\n",
        "        self.conv2d_3 = nn.Conv2d(d*2,d*4, 4,2,1)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(d*4)\n",
        "        self.conv2d_4 = nn.Conv2d(d*4,d*8, 4,2,1)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(d*8)\n",
        "        self.conv2d_5 = nn.Conv2d(d*8,d*8,4,2,1)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(d*8)\n",
        "        self.conv2d_6 = nn.Conv2d(d*8,1,3,1,1)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "    def forward(self, x):\n",
        "      \n",
        "        x = self.leaky(self.conv2d_1(x))\n",
        "        x = self.leaky(self.batchnorm2(self.conv2d_2(x)))\n",
        "        x = self.leaky(self.batchnorm3(self.conv2d_3(x)))\n",
        "        x = self.leaky(self.batchnorm4(self.conv2d_4(x)))\n",
        "        x = self.leaky(self.batchnorm5(self.conv2d_5(x)))\n",
        "        x = self.conv2d_6(x)\n",
        "\n",
        "        return x\n",
        "    def get_name(self):\n",
        "      return 'Critic'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9v_Szs9tFpl"
      },
      "source": [
        "# **Loss Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8nA6RfXtIUo"
      },
      "source": [
        "def calculate_disc_loss(loss_type,smooth_labels,cur_batch_size,real,fake,d,fake_prediction_labels,real_prediction_labels,device):\n",
        "  real_label = 0.9\n",
        "  fake_label = 0.1\n",
        "  if loss_type == 'mse':\n",
        "    if smooth_labels:\n",
        "      real_loss = nn.MSELoss()(real_prediction_labels,torch.full(real_prediction_labels.shape, real_label, device=device))\n",
        "      fake_loss = nn.MSELoss()(fake_prediction_labels,torch.full(fake_prediction_labels.shape, fake_label, device=device))\n",
        "    else:\n",
        "      real_loss = nn.MSELoss()(real_prediction_labels,torch.ones_like(real_prediction_labels))\n",
        "      fake_loss = nn.MSELoss()(fake_prediction_labels,torch.zeros_like(fake_prediction_labels))\n",
        "    loss = real_loss + fake_loss\n",
        "\n",
        "  elif loss_type == 'wasserstein':\n",
        "\n",
        "    epsilon = torch.rand(cur_batch_size, 1, 1, 1, device=device, requires_grad=True)\n",
        "    mixed_images = real * epsilon + fake.detach() * (1 - epsilon)\n",
        "    mixed_scores = d(mixed_images)\n",
        "\n",
        "    gradient = torch.autograd.grad(\n",
        "        inputs=mixed_images,\n",
        "        outputs=mixed_scores,\n",
        "        grad_outputs=torch.ones_like(mixed_scores), \n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "    )[0]\n",
        "\n",
        "    gradient_penalty = ((gradient.view(len(gradient), -1).norm(2, dim=1)-1)**2).mean()\n",
        "    loss = torch.mean(fake_prediction_labels) - torch.mean(real_prediction_labels) + 10.0*gradient_penalty\n",
        "  \n",
        "  return loss\n",
        "\n",
        "def calculate_gen_loss(loss_type,smooth_labels, fake_prediction_labels,lambda_weight,fake,real):\n",
        "  real_label = 0.9\n",
        "  if loss_type == 'mse':\n",
        "    if smooth_labels:\n",
        "      loss = nn.MSELoss()(fake_prediction_labels,torch.full(fake_prediction_labels.shape, real_label, device=device)) + lambda_weight*nn.L1Loss()(fake,real)\n",
        "    else:\n",
        "      loss = nn.MSELoss()(fake_prediction_labels,torch.ones_like(fake_prediction_labels)) + lambda_weight*nn.L1Loss()(fake,real)\n",
        "\n",
        "  elif loss_type == 'wasserstein':\n",
        "    loss = -torch.mean(fake_prediction_labels) + lambda_weight*nn.L1Loss()(fake,real)\n",
        " \n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Dp4ClpAAnJv"
      },
      "source": [
        "# **Train GAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNAkbTip4-eV"
      },
      "source": [
        "def train_gan(generator, discriminator, data, dir, imgs_path, loss, n_epochs, disc_lr, gen_lr, z_dim, lambda_weight , smooth_labels):\n",
        "  generator.to(device)\n",
        "  discriminator.to(device)\n",
        "\n",
        "  init_weights(generator)\n",
        "  init_weights(discriminator)\n",
        "  \n",
        "  n_batches = len(data)\n",
        "  num_of_params_g = sum(p.numel() for p in generator.parameters() if p.requires_grad)\n",
        "  num_of_params_d = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)\n",
        "\n",
        "  num_of_params = num_of_params_d+num_of_params_g\n",
        "\n",
        "  print('Shape of the generated image: ({},{})'.format(512,512))\n",
        "\n",
        "  gen_opt = torch.optim.AdamW(generator.parameters(),lr=gen_lr,betas =(0.5,0.99))\n",
        "  disc_opt = torch.optim.AdamW(discriminator.parameters(),lr=disc_lr,betas =(0.5,0.99))\n",
        "  g_scheduler = MultiStepLR(gen_opt,milestones = [100,200])\n",
        "  d_scheduler = MultiStepLR(disc_opt,milestones = [100,200]) \n",
        "\n",
        "  loss_dict = {'Epoch': [],\n",
        "              'Generator Loss': [],\n",
        "              'Discriminator Loss': [],\n",
        "              }\n",
        "\n",
        "\n",
        "  param_dict = {'Generator': [generator.get_name()],\n",
        "                'Discriminator': [discriminator.get_name()],\n",
        "                'Batch Size': [data.batch_size],\n",
        "                'Noise Dimension': [z_dim],\n",
        "                'Loss Function': [loss],\n",
        "                'Label Smoothing': [smooth_labels],\n",
        "                'L1 weight': [lambda_weight],\n",
        "                'Generator Learning Rate': [gen_lr],\n",
        "                'Disriminator Learning Rate': [disc_lr],\n",
        "                'Training Time': [0],\n",
        "                'Model Parameters': [num_of_params]\n",
        "                  }\n",
        "  \n",
        "  check_or_create_dir(0, dir)\n",
        "\n",
        "  training_start = time.time()\n",
        "  for epoch in range(n_epochs):\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "    #Initialize losses\n",
        "    g_loss = 0\n",
        "    d_loss = 0\n",
        "    for real in tqdm(data):\n",
        "      real = real.float().to(device)\n",
        "      cur_batch_size = len(real)\n",
        "      #Discriminator\n",
        "      disc_opt.zero_grad()\n",
        "      real_data= 0.9*real+0.1*torch.randn((real.size()), device=device)\n",
        "      real_prediction_labels = discriminator(real_data)\n",
        "      noise = get_noise(cur_batch_size, z_dim,device)\n",
        "      fake_generated = generator(noise)\n",
        "      fake_data = 0.9*fake_generated.detach()+0.1*torch.randn((fake_generated.size()), device=device)\n",
        "      fake_prediction_labels = discriminator(fake_data.detach())\n",
        "      disc_loss = calculate_disc_loss(loss,smooth_labels,cur_batch_size,real,fake_generated,discriminator,fake_prediction_labels,real_prediction_labels,device)\n",
        "      disc_loss.backward()\n",
        "      disc_opt.step()\n",
        "      d_scheduler.step()\n",
        "\n",
        "      ####Generator####\n",
        "      gen_opt.zero_grad()\n",
        "      fake_generated = generator(get_noise(cur_batch_size, z_dim,device))\n",
        "      fake_data = 0.9*fake_generated+0.1*torch.randn((fake_generated.size()), device=device)\n",
        "      fake_prediction_labels = discriminator(fake_data)\n",
        "      gen_loss = calculate_gen_loss(loss,smooth_labels,fake_prediction_labels,lambda_weight,fake_generated,real)\n",
        "      gen_loss.backward()\n",
        "      gen_opt.step()\n",
        "      g_scheduler.step()\n",
        "\n",
        "      g_loss += gen_loss\n",
        "      d_loss += disc_loss\n",
        "\n",
        "    g_loss = g_loss/n_batches\n",
        "    d_loss = d_loss/n_batches\n",
        "\n",
        "    loss_dict['Epoch'].append(epoch) \n",
        "    loss_dict['Generator Loss'].append(g_loss.item()) \n",
        "    loss_dict['Discriminator Loss'].append(d_loss.item())\n",
        "\n",
        "    print(f\"Epoch: {epoch} Gen Loss: {g_loss.item()} Disc Loss: {d_loss.item()}\")\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "\n",
        "\n",
        "    ####Save the Generator model/parameters/generated images####\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      torch.save(generator., os.path.join(dir,f'generator_{epoch}.pth'))\n",
        "      torch.save(discriminator,os.path.join(dir,f'discriminator_{epoch}.pth'))\n",
        "      plot(loss,epoch,loss_dict['Generator Loss'],loss_dict['Discriminator Loss'],dir)\n",
        "      show_images(real)\n",
        "      show_images(fake_generated)\n",
        "    save_gen_images(dir, imgs_path, device, epoch, z_dim, generator, num_images=25, size=(3, 512, 512))\n",
        "\n",
        "  training_stop = time.time()\n",
        "  param_dict['Training Time'] = (training_stop-training_start)\n",
        "  losses_pd = pd.DataFrame.from_dict(loss_dict) \n",
        "  losses_pd.to_csv(os.path.join(dir,'losses_history.csv'))\n",
        "  param_pd = pd.DataFrame.from_dict(param_dict)\n",
        "  param_pd.to_csv(os.path.join(dir,'parameters.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Df0G4ZFAeoH"
      },
      "source": [
        "# **Train WGAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPa4viGs_w_r"
      },
      "source": [
        "def train_wgan(generator, discriminator, data,all_data, dir, imgs_path, loss, n_epochs, disc_lr, gen_lr, z_dim, lambda_weight , smooth_labels,d_repeats):\n",
        "  init_weights(generator)\n",
        "  init_weights(discriminator)\n",
        "  \n",
        "  model = GAN(generator,discriminator).to(device)\n",
        "  num_of_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  print('Shape of the generated image: ({},{})'.format(512,512))\n",
        "  n_batches = len(data)\n",
        "\n",
        "  gen_lr  = 0.00005\n",
        "  disc_lr = 0.00005\n",
        "\n",
        "  gen_opt = torch.optim.RMSprop(model.gen.parameters(),lr=gen_lr)\n",
        "  disc_opt = torch.optim.RMSprop(model.disc.parameters(),lr=disc_lr)\n",
        "  g_scheduler = MultiStepLR(gen_opt,milestones = [100,199])\n",
        "  d_scheduler = MultiStepLR(disc_opt,milestones = [100,199])\n",
        "\n",
        "  loss_dict = {'Epoch': [],\n",
        "              'Generator Loss': [],\n",
        "              'Discriminator Loss': [],\n",
        "              }\n",
        "\n",
        "  param_dict = {'Generator': [model.gen.get_name()],\n",
        "                'Discriminator': [model.disc.get_name()],\n",
        "                'Discriminator Repeats': [d_repeats],\n",
        "                'Batch Size': [all_imgs_dataloader.batch_size],\n",
        "                'Noise Dimension': [z_dim],\n",
        "                'Loss Function': [loss_type],\n",
        "                'Label Smoothing': [smooth_labels],\n",
        "                'L1 weight': [lambda_weight],\n",
        "                'Generator Learning Rate': [gen_lr],\n",
        "                'Disriminator Learning Rate': [disc_lr],\n",
        "                'Training Time': [0],\n",
        "                'Model Parameters': [num_of_params]\n",
        "                  }\n",
        "\n",
        "  check_or_create_dir(0, dir)\n",
        "\n",
        "\n",
        "  \n",
        "  training_start = time.time()\n",
        "  for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    g_loss = 0\n",
        "    d_loss = 0\n",
        "    for real in tqdm(data):\n",
        "      real = real.float().to(device)\n",
        "      cur_batch_size = len(real)\n",
        "      #Discriminator\n",
        "      loss_disc_iter = 0\n",
        "      for repeat in range(d_repeats):\n",
        "        disc_opt.zero_grad()\n",
        "        real_data= 0.9*real+0.1*torch.randn((real.size()), device=device)\n",
        "        real_prediction_labels = model.disc(real_data)\n",
        "        noise = get_noise(cur_batch_size, z_dim,device)\n",
        "        fake_generated = model.gen(noise)\n",
        "        fake_data = 0.9*fake_generated.detach()+0.1*torch.randn((fake_generated.size()), device=device)\n",
        "        fake_prediction_labels = model.disc(fake_data.detach())\n",
        "        disc_loss = calculate_disc_loss(loss,smooth_labels,cur_batch_size,real,fake_generated,model.disc,fake_prediction_labels,real_prediction_labels,device)\n",
        "        disc_loss.backward()\n",
        "        disc_opt.step()\n",
        "        d_scheduler.step()\n",
        "        loss_disc_iter += disc_loss/d_repeats\n",
        "      disc_loss = loss_disc_iter\n",
        "\n",
        "      ####Generator####\n",
        "      gen_opt.zero_grad()\n",
        "      fake_generated = model.gen(get_noise(cur_batch_size, z_dim,device))\n",
        "      fake_data = 0.9*fake_generated+0.1*torch.randn((fake_generated.size()), device=device)\n",
        "      fake_prediction_labels = model.disc(fake_data)\n",
        "      gen_loss = calculate_gen_loss(loss,smooth_labels,fake_prediction_labels,lambda_weight,fake_generated,real)\n",
        "      gen_loss.backward()\n",
        "      gen_opt.step()\n",
        "      g_scheduler.step()\n",
        "\n",
        "      g_loss += gen_loss\n",
        "      d_loss += disc_loss\n",
        "\n",
        "    g_loss = g_loss/n_batches\n",
        "    d_loss = d_loss/n_batches\n",
        "\n",
        "    loss_dict['Epoch'].append(epoch) \n",
        "    loss_dict['Generator Loss'].append(g_loss.item()) \n",
        "    loss_dict['Discriminator Loss'].append(d_loss.item())\n",
        "\n",
        "    print(f\"Epoch: {epoch} Gen Loss: {g_loss.item()} Disc Loss: {d_loss.item()}\")\n",
        "\n",
        "    ####Save the Generator model/parameters/generated images####\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      plot(loss_type,epoch,loss_dict['Generator Loss'],loss_dict['Discriminator Loss'],dir)\n",
        "      torch.save(model.gen, os.path.join(dir,f'generator_{epoch}.pth'))\n",
        "      torch.save(model.disc,os.path.join(dir,f'discriminator_{epoch}.pth'))\n",
        "      plot(loss,epoch,loss_dict['Generator Loss'],loss_dict['Discriminator Loss'],dir)\n",
        "      show_images(real)\n",
        "      show_images(fake_generated)\n",
        "    save_gen_images(dir, imgs_path, device, epoch, z_dim, model.gen, num_images=25, size=(3, 512, 512))\n",
        "\n",
        "  training_stop = time.time()\n",
        "  param_dict['Training Time'][0] = (training_stop-training_start) \n",
        "  losses_pd = pd.DataFrame.from_dict(loss_dict)\n",
        "  losses_pd.to_csv(os.path.join(dir,'losses_history.csv'))\n",
        "  param_pd = pd.DataFrame.from_dict(param_dict)\n",
        "  param_pd.to_csv(os.path.join(dir,'parameters.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mkx2QY5u-gf"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe2rEaqKZLvg"
      },
      "source": [
        "generator = SAGenerator(128)\n",
        "discriminator = Discriminator()\n",
        "\n",
        "data = all_imgs_dataloader_batch_1\n",
        "dir = '/content/drive/MyDrive/Thesis_Material/SAGAN'\n",
        "imgs_path = os.path.join(dir,'Generated_Images')\n",
        "\n",
        "\n",
        "n_epochs = 200\n",
        "disc_lr = 0.001\n",
        "gen_lr = 0.0002\n",
        "z_dim = 128\n",
        "lambda_weight = 2.0\n",
        "smooth_labels=True\n",
        "gan ='gan'\n",
        "loss_type ='mse'\n",
        "\n",
        "if gan == 'gan':\n",
        "  train_gan(generator, discriminator, data, dir, imgs_path, 'mse', n_epochs, disc_lr, gen_lr, z_dim, lambda_weight , smooth_labels)\n",
        "elif gan == 'wgan':\n",
        "  train_wgan(generator, discriminator, data,all_data, dir, imgs_path, 'wasserstein', n_epochs, disc_lr, gen_lr, z_dim, lambda_weight , smooth_labels,d_repeats = 2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb_gXd3OOCSl"
      },
      "source": [
        "# **Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA6nZKKG1Kgw"
      },
      "source": [
        "#Create an array with all the real images to be used in IMD calculation\n",
        "\n",
        "def from_path_to_numpy(path):\n",
        "  images_list = os.listdir(path)\n",
        "  images_list.sort()\n",
        "  len_dataset = len(images_list)\n",
        "  dataset = np.zeros([len_dataset, 512, 512, 3])\n",
        "  for i in range(len_dataset):\n",
        "      dataset[i] = cv2.resize(cv2.imread(os.path.join(path, images_list[i])), (512, 512))\n",
        "  return dataset\n",
        "\n",
        "real_dir = '/content/drive/MyDrive/sim2real_dataset/sim2real_dataset/backgrounds'\n",
        "test_dir = '/content/drive/My Drive/Thesis_Material'\n",
        "\n",
        "real_dataset = from_path_to_numpy(real_dir)\n",
        "real_dataset = real_dataset.reshape(105,-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAfPiqrX4sfw"
      },
      "source": [
        "real_dir = '/content/drive/MyDrive/sim2real_dataset/sim2real_dataset/backgrounds'\n",
        "test_dir = '/content/drive/My Drive/Thesis_Material'\n",
        "model_list = ['WGAN_64_xavier USED','SNWGAN_64_xavier USED']\n",
        "\n",
        "for model in model_list:\n",
        "\n",
        "  inception_scores = {'Epoch': [],\n",
        "                      'IS': [],\n",
        "                      'IS std': []}\n",
        "\n",
        "  fid_scores = {'Epoch':[],\n",
        "              'FID Score': []}\n",
        "\n",
        "  imd_scores = {'Epoch':[],\n",
        "              'IMD Score': []}\n",
        "\n",
        "\n",
        "  model_dir = os.path.join('/content/drive/My Drive/Thesis_Material',model)\n",
        "  for step in range(0,201,10):\n",
        "    gen = torch.load(os.path.join(model_dir,f'generator_{step}.pth')).to(device)\n",
        "    gen.eval()\n",
        "    fake_path = os.path.join(model_dir,f'fakes_at_step_{step}')\n",
        "    check_or_create_dir(0,fake_path)  \n",
        "    for i in range(105):\n",
        "      img = gen(get_noise(1,128,device)).squeeze(0).permute(1,2,0).detach().cpu().numpy()\n",
        "      im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      cv2.imwrite(os.path.join(fake_path,f'fake_img{i}.jpg'), 255*im_rgb)\n",
        "\n",
        "  print(f'Calculating Evaluation Metrics for {model} ...')\n",
        "\n",
        "  for step in range(0,201,10):\n",
        "    fid = calculate_FID_score(real_dir, os.path.join(model_dir,f'fakes_at_step_{step}'))\n",
        "    fid_scores['Epoch'].append(step)\n",
        "    fid_scores['FID Score'].append(fid)\n",
        "\n",
        "    IS, IS_std = get_inception_score_from_directory(os.path.join(model_dir,f'fakes_at_step_{step}'))\n",
        "    inception_scores['Epoch'].append(step)\n",
        "    inception_scores['IS'].append(IS)\n",
        "    inception_scores['IS std'].append(IS_std)\n",
        "\n",
        "    fake_dataset = from_path_to_numpy(os.path.join(model_dir,f'fakes_at_step_{step}'))\n",
        "    fake_dataset = fake_dataset.reshape(105,-1)\n",
        "    imd = msid_score(real_dataset,fake_dataset)\n",
        "\n",
        "    imd_scores['Epoch'].append(step)\n",
        "    imd_scores['IMD Score'].append(imd)\n",
        "\n",
        "    print(f'At epoch {step}: FID: {fid} IMD: {imd}')\n",
        "\n",
        "  fid_pd = pd.DataFrame.from_dict(fid_scores)\n",
        "  fid_pd.to_csv(os.path.join(model_dir,'fid_scores.csv'))\n",
        "\n",
        "  imd_pd = pd.DataFrame.from_dict(imd_scores)\n",
        "  imd_pd.to_csv(os.path.join(model_dir,'imd_scores.csv'))\n",
        "\n",
        "  is_pd = pd.DataFrame.from_dict(inception_scores)\n",
        "  is_pd.to_csv(os.path.join(model_dir,'inception_scores.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sMv-h6mdiOxP",
        "outputId": "620f8977-291c-4b29-d567-7d205c97d4e4"
      },
      "source": [
        "gan_model_list = ['DCGAN','SNGAN','SAGAN+SN','WGAN+SN','WGAN-GP','WGAN']\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "for model in gan_model_list:\n",
        "  model_dir = os.path.join('/content/drive/My Drive/Thesis_Material',model)\n",
        "  losses = pd.read_csv(os.path.join(model_dir,'imd_scores.csv'))\n",
        "  ax1.plot(np.arange(0,201,10),losses['IMD Score'],label = model)\n",
        "  ax1.legend()\n",
        "  ax1.set_title('IMD for GAN architectures')\n",
        "  ax1.set_xlabel('Epoch')\n",
        "  ax1.set_ylabel('IMD')\n",
        "plt.savefig('/content/drive/My Drive/Thesis_Material/imd_gan_plot.png')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
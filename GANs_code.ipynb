{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GANs_code.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iTIda_sY2cw1",
        "nQoslRppli7c",
        "j1pQUll8F8lJ",
        "Q5gnbkqNF_4I",
        "ibXzH1ZvFYU9",
        "Xf76c-O-6Nys",
        "OaWiY8v9m3AA",
        "HNLkRj_MYM45",
        "Z7_wq--7WUp1",
        "yClSDel92Ixv",
        "I_VeXe8wtQvK",
        "ZwrZrEH7FAeU",
        "H_QvdW5x7dAk",
        "PQJZp2xUWfav",
        "UH_0Mq4wqbQE",
        "AklX4WI-qbQG",
        "ItF_PFOIqbQH",
        "XnDFf0scqbQH",
        "oweTUPLD6j00",
        "-YPDwoD3y9vZ",
        "ljTKmzDUnh6Y",
        "4APyFVpnV-WP",
        "Fc8sxFo-jIht",
        "skeFQ1WCjIh3",
        "AuNesyukmepE",
        "SQmk1EhDmepG",
        "pXB14qkKiOjW",
        "NxrjPA_yiOjX",
        "2Veo1ixiiOjX",
        "JiF3OpF_H7tu",
        "uCAgzyciIaYT",
        "6AoADjVNyMcV",
        "uWUanMkHyMcc",
        "l_XCCAZFyMcd",
        "O9v_Szs9tFpl",
        "pmVjXwrQ2UQT",
        "3Dp4ClpAAnJv",
        "7Df0G4ZFAeoH",
        "rLghq0PDA2kS",
        "5mkx2QY5u-gf",
        "Wb_gXd3OOCSl"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQoslRppli7c"
      },
      "source": [
        "## **Imports**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1pQUll8F8lJ"
      },
      "source": [
        "### **pip installs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D192NIlyo8Jq"
      },
      "source": [
        "!pip install -U albumentations\n",
        "import albumentations\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "!pip install torchgan\n",
        "import torchgan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vaWKhWJLpCe"
      },
      "source": [
        "!pip install pytorch-gan-metrics\n",
        "from pytorch_gan_metrics import (get_inception_score_from_directory)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5gnbkqNF_4I"
      },
      "source": [
        "### **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9d4J03Y6APa",
        "outputId": "fd5a0fd6-27f6-4782-9788-9a964cc4854c"
      },
      "source": [
        "import torch\n",
        "import json\n",
        "import skimage\n",
        "from skimage import io, exposure, img_as_uint, img_as_float\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from scipy import linalg\n",
        "import time\n",
        "from torchsummary import summary\n",
        "import random \n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from argparse import ArgumentParser\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import norm\n",
        "import pickle as pkl\n",
        "import os\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from torchvision.transforms.transforms import RandomHorizontalFlip, RandomVerticalFlip\n",
        "import torchvision.transforms as transforms\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision.utils import make_grid\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torch import Tensor\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.init as init\n",
        "import copy\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numbers\n",
        "import cv2\n",
        "from numpy import cov\n",
        "from numpy import trace\n",
        "from numpy import iscomplexobj\n",
        "from numpy import asarray\n",
        "from numpy.random import randint\n",
        "from scipy.linalg import sqrtm\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.datasets.mnist import load_data\n",
        "from skimage.transform import resize\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "from torch.autograd import Variable\n",
        "from torch import Tensor\n",
        "from torch.nn import Parameter\n",
        "\n",
        "\n",
        "# torch.autograd.set_detect_anomaly(False)\n",
        "# torch.autograd.profiler.profile(False)\n",
        "# torch.autograd.profiler.emit_nvtx(False)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibXzH1ZvFYU9"
      },
      "source": [
        "## **Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hiRYfCzT7xq"
      },
      "source": [
        "clean_imgs_path ='/content/drive/MyDrive/sim2real_dataset/sim2real_dataset/backgrounds'\n",
        "clean_imgs_list = os.listdir(clean_imgs_path)\n",
        "resize_shape = 512 \n",
        "crop_shape = 512\n",
        "\n",
        "class CleanDataset():\n",
        "    def __init__(self,real_dir,real_list, transform = None):\n",
        "\n",
        "        self.real_list = real_list\n",
        "        self.real_dir = real_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.real_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_path = os.path.join(self.real_dir, self.real_list[idx])\n",
        "        real = io.imread(real_path)\n",
        "        real = Image.fromarray(real)\n",
        "        if self.transform:\n",
        "          real = self.transform(real)\n",
        "        else:\n",
        "          real = transforms.ToTensor()(real)\n",
        "\n",
        "        return real\n",
        "\n",
        "class ElasticDataset():\n",
        "    def __init__(self,real_dir,real_list, transform = None):\n",
        "\n",
        "        self.real_list = real_list\n",
        "        self.real_dir = real_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.real_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_path = os.path.join(self.real_dir, self.real_list[idx])\n",
        "        real = cv2.imread(real_path)\n",
        "        real = cv2.cvtColor(real, cv2.COLOR_BGR2RGB)\n",
        "        real = albumentations.Resize(512,512)(image = real)[\"image\"]\n",
        "        real = albumentations.CenterCrop(512,512)(image = real)[\"image\"]\n",
        "        real = RandomElastic(alpha = 10,sigma = 0.1)(img = real)\n",
        "        real = transforms.ToTensor()(real)\n",
        "        return real\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "clean_transformation = transforms.Compose([\n",
        "   transforms.Resize(resize_shape),\n",
        "   transforms.CenterCrop(crop_shape),\n",
        "   transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "random_brightness = transforms.Compose([\n",
        "   transforms.Resize(resize_shape),\n",
        "   transforms.CenterCrop(crop_shape),\n",
        "   transforms.ColorJitter(brightness=0.2),\n",
        "   transforms.ToTensor()\n",
        "])\n",
        "\n",
        "random_flips = transforms.Compose([\n",
        "   transforms.Resize(resize_shape),\n",
        "   transforms.CenterCrop(crop_shape),\n",
        "   transforms.RandomHorizontalFlip(p=1),\n",
        "   transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "full_imgs_data = CleanDataset(clean_imgs_path,clean_imgs_list,transform = None)\n",
        "\n",
        "\n",
        "#Clean Dataset\n",
        "clean_imgs_data = CleanDataset(clean_imgs_path,clean_imgs_list,transform = clean_transformation)\n",
        "#Random Brightness Dataset\n",
        "brightness_imgs_data = CleanDataset(clean_imgs_path,clean_imgs_list,transform = random_brightness)\n",
        "#Random Flips Dataset\n",
        "flips_imgs_data = CleanDataset(clean_imgs_path,clean_imgs_list,transform = random_flips)\n",
        "#Elastic Deformation\n",
        "elastic_imgs_data = ElasticDataset(clean_imgs_path,clean_imgs_list,transform=None)\n",
        "\n",
        "#Concatenate Datasets and create DataLoader\n",
        "all_data = ConcatDataset([clean_imgs_data,flips_imgs_data,brightness_imgs_data,elastic_imgs_data])\n",
        "all_imgs_dataloader = DataLoader(all_data, batch_size=8, shuffle=True,num_workers=0)\n",
        "\n",
        "all_imgs_dataloader_batch_1 = DataLoader(all_data, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf76c-O-6Nys"
      },
      "source": [
        "## **Useful Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCVLl6D96M0O"
      },
      "source": [
        "def show_images(image_tensor, num_images=8):\n",
        "\n",
        "    image_unflat = image_tensor.detach().cpu()\n",
        "    image_grid = make_grid(image_unflat, nrow=4,padding = 10, pad_value = 1)\n",
        "    plt.figure()\n",
        "    plt.imshow(image_grid.permute(1, 2, 0))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def check_or_create_dir(e,d):\n",
        "  if e == 0:\n",
        "    check_directory = os.path.isdir(d)\n",
        "    if check_directory == False:\n",
        "      os.makedirs(d)\n",
        "      print(\"created folder : \", d)\n",
        "    else:\n",
        "      print(d, \"folder already exists.\")\n",
        "\n",
        "\n",
        "def plot(loss,cur_epochs,gen_losses,disc_losses,dir):\n",
        "  if cur_epochs == 0:\n",
        "    pass\n",
        "  else:\n",
        "    if loss != 'wasserstein':\n",
        "      gen_losses = np.array(gen_losses)\n",
        "      disc_losses = np.array(disc_losses)\n",
        "\n",
        "      fig = plt.figure()\n",
        "      plt.plot(np.arange(len(gen_losses)),gen_losses,label = 'Gen Loss')\n",
        "      plt.plot(np.arange(len(disc_losses)),disc_losses,label='Disc Loss')\n",
        "      plt.title('Losses',fontsize = 15)\n",
        "      plt.xlabel('Epochs',fontsize = 10)\n",
        "      plt.ylabel('Loss', fontsize = 10)\n",
        "      plt.legend(prop={'size': 10})\n",
        "      plt.savefig(f\"{dir}/loss.png\")\n",
        "      plt.show()\n",
        "    else:\n",
        "      gen_losses = np.array(gen_losses)\n",
        "      fig = plt.figure()\n",
        "      plt.plot(np.arange(len(gen_losses)),gen_losses)\n",
        "      plt.title('Generator Loss',fontsize = 15)\n",
        "      plt.xlabel('Epochs',fontsize = 10)\n",
        "      plt.ylabel('Loss', fontsize = 10)\n",
        "      plt.savefig(f\"{dir}/gen_loss.png\")\n",
        "      plt.show()\n",
        "      disc_losses = np.array(disc_losses)\n",
        "      fig = plt.figure()\n",
        "      plt.plot(np.arange(len(disc_losses)),disc_losses)\n",
        "      plt.title('Discriminator Loss',fontsize = 15)\n",
        "      plt.xlabel('Epochs',fontsize = 10)\n",
        "      plt.ylabel('Loss', fontsize = 10)\n",
        "      plt.savefig(f\"{dir}/disc_loss.png\")\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def get_noise(n_samples, z_dim, device):\n",
        "    return torch.randn(n_samples,z_dim,device = device)\n",
        "\n",
        "def save_gen_images(dir,g_imgs_path, device, cur_epoch, z_dim, gen, num_images=8, size=(3, 512, 512)):\n",
        "\n",
        "  # if cur_epoch == 0:\n",
        "  check_directory = os.path.isdir(g_imgs_path)\n",
        "  if check_directory == False:\n",
        "    os.makedirs(g_imgs_path)\n",
        "    print(\"created folder : \", g_imgs_path)\n",
        "  else:\n",
        "    print(g_imgs_path, \"folder already exists.\")\n",
        "\n",
        "  gen.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    noise = get_noise(num_images,z_dim,device)\n",
        "    fakes = gen(noise)#[-1]\n",
        "    imgs = fakes.detach().cpu().view(-1,*size)\n",
        "    image_grid = make_grid(imgs, nrow=5,padding = 10, pad_value = 1)\n",
        "    fig = plt.figure(figsize=[50,50])\n",
        "    plt.imshow(image_grid.permute(1, 2, 0))\n",
        "    plt.axis('off')\n",
        "    plt.savefig(f\"{g_imgs_path}/gen_imgs_epoch{cur_epoch}.png\", bbox_inches = 'tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def init_weights(net, init_type='orthogonal', init_gain=0.02):\n",
        "    \"\"\"Initialize network weights.\n",
        "    Parameters:\n",
        "        net (network)   -- network to be initialized\n",
        "        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
        "        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n",
        "    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n",
        "    work better for some applications. Feel free to try yourself.\n",
        "    \"\"\"\n",
        "    def init_func(m):  # define the initialization function\n",
        "        classname = m.__class__.__name__ \n",
        "        if hasattr(m, 'weight') and classname.find('Conv') != -1:\n",
        "          if init_type == 'normal':\n",
        "              init.normal_(m.weight.data, 0.0, init_gain)\n",
        "          elif init_type == 'xavier':\n",
        "              init.xavier_normal_(m.weight.data, gain=init_gain)\n",
        "          elif init_type == 'kaiming':\n",
        "              init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "          elif init_type == 'orthogonal':\n",
        "              init.orthogonal_(m.weight.data, gain=init_gain)\n",
        "          else:\n",
        "              raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
        "          if hasattr(m, 'bias') and m.bias is not None:\n",
        "              init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
        "            init.normal_(m.weight.data, 1.0, init_gain)\n",
        "            init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    net.apply(init_func)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNLkRj_MYM45"
      },
      "source": [
        "## **GAN Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CegYxtw8Wk_B"
      },
      "source": [
        "class GAN(nn.Module):\n",
        "\n",
        "    def __init__(self, generator, discriminator):\n",
        "        super(GAN, self).__init__()\n",
        "        self.gen = generator\n",
        "        self.disc = discriminator\n",
        "        self.name = 'GAN'\n",
        "    \n",
        "    def get_gen(self):\n",
        "        return self.gen\n",
        "    \n",
        "    def get_disc(self):\n",
        "        return self.disc\n",
        "\n",
        "    def name(self):\n",
        "      return self.name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yClSDel92Ixv"
      },
      "source": [
        "## **FID (Fretchet Inception Distance)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQcI9dkL4QmO"
      },
      "source": [
        "def calculate_FID_score(real_path, fake_path):\n",
        "        \n",
        "    def load_images(path):\n",
        "        \n",
        "        images_list = os.listdir(path)\n",
        "        images_list.sort()\n",
        "        len_dataset = len(images_list)\n",
        "        dataset = np.zeros([len_dataset, 576, 576, 3])\n",
        "        for i in range(len_dataset):\n",
        "           # if i % 10 == 0:\n",
        "                #print(i)\n",
        "            dataset[i] = cv2.resize(cv2.imread(os.path.join(path, images_list[i])), (576, 576))\n",
        "        return dataset\n",
        "\n",
        " \n",
        "\n",
        "    # scale an array of images to a new size\n",
        "    def scale_images(images, new_shape):\n",
        "        images_list = list()\n",
        "        for image in images:\n",
        "            # resize with nearest neighbor interpolation\n",
        "            new_image = resize(image, new_shape, 0)\n",
        "            # store\n",
        "            images_list.append(new_image)\n",
        "        return asarray(images_list)\n",
        "    \n",
        "    # calculate frechet inception distance\n",
        "    def calculate_fid(model, images1, images2):\n",
        "        # calculate activations\n",
        "        act1 = model.predict(images1)\n",
        "        act2 = model.predict(images2)\n",
        "        # calculate mean and covariance statistics\n",
        "        mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
        "        mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
        "        # calculate sum squared difference between means\n",
        "        ssdiff = np.sum((mu1 - mu2)**2.0)\n",
        "        # calculate sqrt of product between cov\n",
        "        covmean = sqrtm(sigma1.dot(sigma2))\n",
        "        # check and correct imaginary numbers from sqrt\n",
        "        if iscomplexobj(covmean):\n",
        "            covmean = covmean.real\n",
        "        # calculate score\n",
        "        fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "        return fid\n",
        "\n",
        " \n",
        "\n",
        "    # prepare the inception v3 model\n",
        "    model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
        "    # define two fake collections of images\n",
        "    images1 = load_images(fake_path)\n",
        "    images2 = load_images(real_path)\n",
        "    #print('Prepared', images1.shape, images2.shape)\n",
        "    # convert integer to floating point values\n",
        "    images1 = images1.astype('float32')\n",
        "    images2 = images2.astype('float32')\n",
        "    # resize images\n",
        "    images1 = scale_images(images1, (299,299,3))\n",
        "    images2 = scale_images(images2, (299,299,3))\n",
        "    #print('Scaled', images1.shape, images2.shape)\n",
        "    # pre-process images\n",
        "    images1 = preprocess_input(images1)\n",
        "    images2 = preprocess_input(images2)\n",
        "\n",
        " \n",
        "\n",
        "    # fid between images1 and images2\n",
        "    fid = calculate_fid(model, images1, images2)\n",
        "    # print('FID (different): %.3f' % fid)\n",
        "    return fid\n",
        "\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_VeXe8wtQvK"
      },
      "source": [
        "## **Elastic Deformation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F23MAcm8rvn8"
      },
      "source": [
        "class RandomElastic(object):\n",
        "    \"\"\"Random Elastic transformation by CV2 method on image by alpha, sigma parameter.\n",
        "        # you can refer to:  https://blog.csdn.net/qq_27261889/article/details/80720359\n",
        "        # https://blog.csdn.net/maliang_1993/article/details/82020596\n",
        "        # https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.map_coordinates.html#scipy.ndimage.map_coordinates\n",
        "    Args:\n",
        "        alpha (float): alpha value for Elastic transformation, factor\n",
        "        if alpha is 0, output is original whatever the sigma;\n",
        "        if alpha is 1, output only depends on sigma parameter;\n",
        "        if alpha < 1 or > 1, it zoom in or out the sigma's Relevant dx, dy.\n",
        "        sigma (float): sigma value for Elastic transformation, should be \\ in (0.05,0.1)\n",
        "        mask (PIL Image) if not assign, set None.\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha, sigma):\n",
        "        assert isinstance(alpha, numbers.Number) and isinstance(sigma, numbers.Number), \\\n",
        "            \"alpha and sigma should be a single number.\"\n",
        "        assert 0.05 <= sigma <= 0.1, \\\n",
        "            \"In pathological image, sigma should be in (0.05,0.1)\"\n",
        "        self.alpha = alpha\n",
        "        self.sigma = sigma\n",
        "\n",
        "    @staticmethod\n",
        "    def RandomElasticCV2(img, alpha, sigma, mask=None):\n",
        "        alpha = img.shape[1] * alpha\n",
        "        sigma = img.shape[1] * sigma\n",
        "        if mask is not None:\n",
        "            mask = np.array(mask).astype(np.uint8)\n",
        "            img = np.concatenate((img, mask[..., None]), axis=2)\n",
        "\n",
        "        shape = img.shape\n",
        "\n",
        "        dx = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "        dy = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "        # dz = np.zeros_like(dx)\n",
        "\n",
        "        x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
        "        indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
        "\n",
        "        img = map_coordinates(img, indices, order=0, mode='reflect').reshape(shape)\n",
        "        if mask is not None:\n",
        "            return Image.fromarray(img[..., :3]), Image.fromarray(img[..., 3])\n",
        "        else:\n",
        "            #return Image.fromarray(img)\n",
        "            return img\n",
        "    def __call__(self, img, mask=None):\n",
        "        return self.RandomElasticCV2(np.array(img), self.alpha, self.sigma, mask)\n",
        "\n",
        "    def __repr__(self):\n",
        "        format_string = self.__class__.__name__ + '(alpha value={0})'.format(self.alpha)\n",
        "        format_string += ', sigma={0}'.format(self.sigma)\n",
        "        format_string += ')'\n",
        "        return format_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FulAkTE1rxps"
      },
      "source": [
        "# img = clean_imgs_data[17]\n",
        "# elastic_deformation = RandomElastic(alpha = 15,sigma = 0.1)\n",
        "# new_img = elastic_deformation(img.permute(1,2,0).numpy())\n",
        "# #print(new_img)\n",
        "# plt.imshow(new_img)\n",
        "# plt.show()\n",
        "# plt.imshow(img.permute(1,2,0).numpy())\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWSxg7wg2UNK"
      },
      "source": [
        "# img = cv2.imread(os.path.join(clean_imgs_path,'img_022.png'),cv2.IMREAD_COLOR)\n",
        "# cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "# def draw_grid(im, grid_size):\n",
        "#     # Draw grid lines\n",
        "#     for i in range(0, im.shape[1], grid_size):\n",
        "#         cv2.line(im, (i, 0), (i, im.shape[0]), \tcolor = (255,255,255), thickness = 2)\n",
        "#     for j in range(0, im.shape[0], grid_size):\n",
        "#         cv2.line(im, (0, j), (im.shape[1], j), \tcolor = (255,255,255), thickness = 2)\n",
        "\n",
        "# save_dir = '/content/drive/My Drive/Thesis_Material'\n",
        "# draw_grid(img, 150)\n",
        "# img_t = transforms.Compose([\n",
        "#    transforms.Resize(resize_shape),\n",
        "#    transforms.CenterCrop(crop_shape)])(Image.fromarray(img))\n",
        "# img_t = np.array(img_t)\n",
        "# cv2_imshow(img_t)\n",
        "# cv2.imwrite(os.path.join(save_dir,'example_with_grid_before.png'),img_t)\n",
        "# elastic_deformation = RandomElastic(alpha = 15,sigma = 0.1)\n",
        "# new_img = elastic_deformation(img_t)\n",
        "# cv2_imshow(new_img)\n",
        "# cv2.imwrite(os.path.join(save_dir,'example_with_grid_after.png'),new_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_QvdW5x7dAk"
      },
      "source": [
        "## **Self-Attention Block**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY7debaU7gjb"
      },
      "source": [
        "\n",
        "class Self_Attn(nn.Module):\n",
        "    \"\"\" Self attention Layer\"\"\"\n",
        "    def __init__(self,in_dim,activation):\n",
        "        super(Self_Attn,self).__init__()\n",
        "        self.chanel_in = in_dim\n",
        "        self.activation = activation\n",
        "        \n",
        "        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
        "        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
        "        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "        self.softmax  = nn.Softmax(dim=-1) #\n",
        "    def forward(self,x):\n",
        "        \"\"\"\n",
        "            inputs :\n",
        "                x : input feature maps( B X C X W X H)\n",
        "            returns :\n",
        "                out : self attention value + input feature \n",
        "                attention: B X N X N (N is Width*Height)\n",
        "        \"\"\"\n",
        "        m_batchsize,C,width ,height = x.size()\n",
        "        proj_query  = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1) # B X CX(N)\n",
        "        proj_key =  self.key_conv(x).view(m_batchsize,-1,width*height) # B X C x (*W*H)\n",
        "        energy =  torch.bmm(proj_query,proj_key) # transpose check\n",
        "        attention = self.softmax(energy) # BX (N) X (N) \n",
        "        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) # B X C X N\n",
        "\n",
        "        out = torch.bmm(proj_value,attention.permute(0,2,1) )\n",
        "        out = out.view(m_batchsize,C,width,height)\n",
        "        \n",
        "        out = self.gamma*out + x\n",
        "        return out,attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQJZp2xUWfav"
      },
      "source": [
        "## **IMD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeAVyhGQWhhY"
      },
      "source": [
        "import scipy.sparse as sps\n",
        "\n",
        "\n",
        "def _lanczos_m(A, m, nv, rademacher, SV=None):\n",
        "    '''\n",
        "    Lanczos algorithm computes symmetric m x m tridiagonal matrix T and matrix V with orthogonal rows\n",
        "        constituting the basis of the Krylov subspace K_m(A, x),\n",
        "        where x is an arbitrary starting unit vector.\n",
        "        This implementation parallelizes `nv` starting vectors.\n",
        "    \n",
        "    Arguments:\n",
        "        m: number of Lanczos steps\n",
        "        nv: number of random vectors\n",
        "        rademacher: True to use Rademacher distribution, \n",
        "                    False - standard normal for random vectors\n",
        "        SV: specified starting vectors\n",
        "    \n",
        "    Returns:\n",
        "        T: a nv x m x m tensor, T[i, :, :] is the ith symmetric tridiagonal matrix\n",
        "        V: a n x m x nv tensor, V[:, :, i] is the ith matrix with orthogonal rows \n",
        "    '''\n",
        "    orthtol = 1e-5\n",
        "    if type(SV) != np.ndarray:\n",
        "        if rademacher:\n",
        "            SV = np.sign(np.random.randn(A.shape[0], nv))\n",
        "        else:\n",
        "            SV = np.random.randn(A.shape[0], nv)  # init random vectors in columns: n x nv\n",
        "    V = np.zeros((SV.shape[0], m, nv))\n",
        "    T = np.zeros((nv, m, m))\n",
        "\n",
        "    np.divide(SV, np.linalg.norm(SV, axis=0), out=SV)  # normalize each column\n",
        "    V[:, 0, :] = SV\n",
        "\n",
        "    w = A.dot(SV)\n",
        "    alpha = np.einsum('ij,ij->j', w, SV)\n",
        "    w -= alpha[None, :] * SV\n",
        "    beta = np.einsum('ij,ij->j', w, w)\n",
        "    np.sqrt(beta, beta)\n",
        "\n",
        "    T[:, 0, 0] = alpha\n",
        "    T[:, 0, 1] = beta\n",
        "    T[:, 1, 0] = beta\n",
        "\n",
        "    np.divide(w, beta[None, :], out=w)\n",
        "    V[:, 1, :] = w\n",
        "    t = np.zeros((m, nv))\n",
        "\n",
        "    for i in range(1, m):\n",
        "        SVold = V[:, i - 1, :]\n",
        "        SV = V[:, i, :]\n",
        "\n",
        "        w = A.dot(SV)  # sparse @ dense\n",
        "        w -= beta[None, :] * SVold  # n x nv\n",
        "        np.einsum('ij,ij->j', w, SV, out=alpha)\n",
        "\n",
        "        T[:, i, i] = alpha\n",
        "\n",
        "        if i < m - 1:\n",
        "            w -= alpha[None, :] * SV  # n x nv\n",
        "            # reortho\n",
        "            np.einsum('ijk,ik->jk', V, w, out=t)\n",
        "            w -= np.einsum('ijk,jk->ik', V, t)\n",
        "            np.einsum('ij,ij->j', w, w, out=beta)\n",
        "            np.sqrt(beta, beta)\n",
        "            np.divide(w, beta[None, :], out=w)\n",
        "\n",
        "            T[:, i, i + 1] = beta\n",
        "            T[:, i + 1, i] = beta\n",
        "\n",
        "            # more reotho\n",
        "            innerprod = np.einsum('ijk,ik->jk', V, w)\n",
        "            reortho = False\n",
        "            for _ in range(100):\n",
        "                if not (innerprod > orthtol).sum():\n",
        "                    reortho = True\n",
        "                    break\n",
        "                np.einsum('ijk,ik->jk', V, w, out=t)\n",
        "                w -= np.einsum('ijk,jk->ik', V, t)\n",
        "                np.divide(w, np.linalg.norm(w, axis=0)[None, :], out=w)\n",
        "                innerprod = np.einsum('ijk,ik->jk', V, w)\n",
        "\n",
        "            V[:, i + 1, :] = w\n",
        "\n",
        "            if (np.abs(beta) > 1e-6).sum() == 0 or not reortho:\n",
        "                break\n",
        "    return T, V\n",
        "\n",
        "\n",
        "def _slq(A, m, niters, rademacher):\n",
        "    '''\n",
        "    Compute the trace of matrix exponential\n",
        "    \n",
        "    Arguments:\n",
        "        A: square matrix in trace(exp(A))\n",
        "        m: number of Lanczos steps\n",
        "        niters: number of quadratures (also, the number of random vectors in the hutchinson trace estimator)\n",
        "        rademacher: True to use Rademacher distribution, False - standard normal for random vectors in Hutchinson\n",
        "    Returns:\n",
        "        trace: estimate of trace of matrix exponential\n",
        "    '''\n",
        "    T, _ = _lanczos_m(A, m, niters, rademacher)\n",
        "    eigvals, eigvecs = np.linalg.eigh(T)\n",
        "    expeig = np.exp(eigvals)\n",
        "    sqeigv1 = np.power(eigvecs[:, 0, :], 2)\n",
        "    trace = A.shape[-1] * (expeig * sqeigv1).sum() / niters\n",
        "    return trace\n",
        "\n",
        "\n",
        "def _slq_ts(A, m, niters, ts, rademacher):\n",
        "    '''\n",
        "    Compute the trace of matrix exponential\n",
        "    \n",
        "    Arguments:\n",
        "        A: square matrix in trace(exp(-t*A)), where t is temperature\n",
        "        m: number of Lanczos steps\n",
        "        niters: number of quadratures (also, the number of random vectors in the hutchinson trace estimator)\n",
        "        ts: an array with temperatures\n",
        "        rademacher: True to use Rademacher distribution, False - standard normal for random vectors in Hutchinson\n",
        "    Returns:\n",
        "        trace: estimate of trace of matrix exponential across temperatures `ts`\n",
        "    '''\n",
        "    T, _ = _lanczos_m(A, m, niters, rademacher)\n",
        "    eigvals, eigvecs = np.linalg.eigh(T)\n",
        "    expeig = np.exp(-np.outer(ts, eigvals)).reshape(ts.shape[0], niters, m)\n",
        "    sqeigv1 = np.power(eigvecs[:, 0, :], 2)\n",
        "    traces = A.shape[-1] * (expeig * sqeigv1).sum(-1).mean(-1)\n",
        "    return traces\n",
        "\n",
        "\n",
        "def _slq_ts_fs(A, m, niters, ts, rademacher, fs):\n",
        "    '''\n",
        "    Compute the trace of matrix functions\n",
        "    \n",
        "    Arguments:\n",
        "        A: square matrix in trace(exp(-t*A)), where t is temperature\n",
        "        m: number of Lanczos steps\n",
        "        niters: number of quadratures (also, the number of random vectors in the hutchinson trace estimator)\n",
        "        ts: an array with temperatures\n",
        "        rademacher: True to use Rademacher distribution, else - standard normal for random vectors in Hutchinson\n",
        "        fs: a list of functions\n",
        "    Returns:\n",
        "        traces: estimate of traces for each of the functions in fs\n",
        "    '''\n",
        "    T, _ = _lanczos_m(A, m, niters, rademacher)\n",
        "    eigvals, eigvecs = np.linalg.eigh(T)\n",
        "    traces = np.zeros((len(fs), len(ts)))\n",
        "    for i, f in enumerate(fs):\n",
        "        expeig = f(-np.outer(ts, eigvals)).reshape(ts.shape[0], niters, m)\n",
        "        sqeigv1 = np.power(eigvecs[:, 0, :], 2)\n",
        "        traces[i, :] = A.shape[-1] * (expeig * sqeigv1).sum(-1).mean(-1)\n",
        "    return traces\n",
        "\n",
        "\n",
        "def slq_red_var(A, m, niters, ts, rademacher):\n",
        "    '''\n",
        "    Compute the trace of matrix exponential with reduced variance\n",
        "    \n",
        "    Arguments:\n",
        "        A: square matrix in trace(exp(-t*A)), where t is temperature\n",
        "        m: number of Lanczos steps\n",
        "        niters: number of quadratures (also, the number of random vectors in the hutchinson trace estimator)\n",
        "        ts: an array with temperatures\n",
        "    Returns:\n",
        "        traces: estimate of trace for each temperature value in `ts`\n",
        "    '''\n",
        "    fs = [np.exp, lambda x: x]\n",
        "\n",
        "    traces = _slq_ts_fs(A, m, niters, ts, rademacher, fs)\n",
        "    subee = traces[0, :] - traces[1, :] / np.exp(ts)\n",
        "    sub = - ts * A.shape[0] / np.exp(ts)\n",
        "    return subee + sub\n",
        "\n",
        "\n",
        "from scipy.sparse import lil_matrix, diags, eye\n",
        "\n",
        "\n",
        "def np_euc_cdist(data):\n",
        "    dd = np.sum(data*data, axis=1)\n",
        "    dist = -2*np.dot(data, data.T)\n",
        "    dist += dd + dd[:, np.newaxis] \n",
        "    np.fill_diagonal(dist, 0)\n",
        "    np.sqrt(dist, dist)\n",
        "    return dist\n",
        "\n",
        "\n",
        "def construct_graph_sparse(data, k):\n",
        "    n = len(data)\n",
        "    spmat = lil_matrix((n, n))\n",
        "    dd = np.sum(data*data, axis=1)\n",
        "    \n",
        "    for i in range(n):\n",
        "        dists = dd - 2*data[i, :].dot(data.T)\n",
        "        inds = np.argpartition(dists, k+1)[:k+1]\n",
        "        inds = inds[inds!=i]\n",
        "        spmat[i, inds] = 1\n",
        "            \n",
        "    return spmat.tocsr()\n",
        "\n",
        "\n",
        "def construct_graph_kgraph(data, k):\n",
        "    import pykgraph\n",
        "\n",
        "    n = len(data)\n",
        "    spmat = lil_matrix((n, n))\n",
        "    index = pykgraph.KGraph(data, 'euclidean')\n",
        "    index.build(reverse=0, K=2 * k + 1, L=2 * k + 50)\n",
        "    result = index.search(data, K=k + 1)[:, 1:]\n",
        "    spmat[np.repeat(np.arange(n), k, 0), result.ravel()] = 1\n",
        "    return spmat.tocsr()\n",
        "\n",
        "\n",
        "def _laplacian_sparse(A, normalized=True):\n",
        "    D = A.sum(1).A1\n",
        "    if normalized:\n",
        "        Dsqrt = diags(1/np.sqrt(D))\n",
        "        L = eye(A.shape[0]) - Dsqrt.dot(A).dot(Dsqrt)\n",
        "    else:\n",
        "        L = diags(D) - A\n",
        "    return L\n",
        "\n",
        "import scipy.sparse as sps\n",
        "\n",
        "EPSILON = 1e-6\n",
        "NORMALIZATION = 1e6\n",
        "\n",
        "\n",
        "def _build_graph(data, k=5, graph_builder='sparse', normalized=True):\n",
        "    \"\"\"\n",
        "    Return Laplacian from data or load preconstructed from path\n",
        "    Arguments:\n",
        "        data: samples\n",
        "        k: number of neighbours for graph construction\n",
        "        graph_builder: if 'kgraph', use faster graph construction\n",
        "        normalized: if True, use nnormalized Laplacian\n",
        "    Returns:\n",
        "        L: Laplacian of the graph constructed with data\n",
        "    \"\"\"\n",
        "    if graph_builder == 'sparse':\n",
        "        A = construct_graph_sparse(data, k)\n",
        "    elif graph_builder == 'kgraph':\n",
        "        A = construct_graph_kgraph(data, k)\n",
        "    else:\n",
        "        raise Exception('Please specify graph builder: sparse or kgraph.')\n",
        "    A = (A + A.T) / 2\n",
        "    A.data = np.ones(A.data.shape)\n",
        "    L = _laplacian_sparse(A, normalized)\n",
        "    return L\n",
        "\n",
        "\n",
        "def _normalize_msid(msid, normalization, n, k, ts):\n",
        "    normed_msid = msid.copy()\n",
        "    if normalization == 'empty':\n",
        "        normed_msid /= n\n",
        "    elif normalization == 'complete':\n",
        "        normed_msid /= (1 + (n - 1) * np.exp(-(1 + 1 / (n - 1)) * ts))\n",
        "    elif normalization == 'er':\n",
        "        xs = np.linspace(0, 1, n)\n",
        "        er_spectrum = 4 / np.sqrt(k) * xs + 1 - 2 / np.sqrt(k)\n",
        "        er_msid = np.exp(-np.outer(ts, er_spectrum)).sum(-1)\n",
        "        normed_msid = normed_msid / (er_msid + EPSILON)\n",
        "    elif normalization == 'none' or normalization is None:\n",
        "        pass\n",
        "    else:\n",
        "        raise ValueError('Unknown normalization parameter!')\n",
        "    return normed_msid\n",
        "\n",
        "\n",
        "def msid_score(x, y, ts=np.logspace(-1, 1, 256), k=5, m=10, niters=100, rademacher=False, graph_builder='sparse',\n",
        "              msid_mode='max', normalized_laplacian=True, normalize='empty'):\n",
        "    '''\n",
        "    Compute the msid score between two samples, x and y\n",
        "    Arguments:\n",
        "        x: x samples\n",
        "        y: y samples\n",
        "        ts: temperature values\n",
        "        k: number of neighbours for graph construction\n",
        "        m: Lanczos steps in SLQ\n",
        "        niters: number of starting random vectors for SLQ\n",
        "        rademacher: if True, sample random vectors from Rademacher distributions, else sample standard normal distribution\n",
        "        graph_builder: if 'kgraph', uses faster graph construction (options: 'sparse', 'kgraph')\n",
        "        msid_mode: 'l2' to compute the l2 norm of the distance between `msid1` and `msid2`;\n",
        "                'max' to find the maximum abosulute difference between two descriptors over temperature\n",
        "        normalized_laplacian: if True, use normalized Laplacian\n",
        "        normalize: 'empty' for average heat kernel (corresponds to the empty graph normalization of NetLSD),\n",
        "                'complete' for the complete, 'er' for erdos-renyi\n",
        "                normalization, 'none' for no normalization\n",
        "    Returns:\n",
        "        msid_score: the scalar value of the distance between discriptors\n",
        "    '''\n",
        "    normed_msidx = msid_descriptor(x, ts, k, m, niters, rademacher, graph_builder, normalized_laplacian, normalize)\n",
        "    normed_msidy = msid_descriptor(y, ts, k, m, niters, rademacher, graph_builder, normalized_laplacian, normalize)\n",
        "\n",
        "    c = np.exp(-2 * (ts + 1 / ts))\n",
        "\n",
        "    if msid_mode == 'l2':\n",
        "        score = np.linalg.norm(normed_msidx - normed_msidy)\n",
        "    elif msid_mode == 'max':\n",
        "        score = np.amax(c * np.abs(normed_msidx - normed_msidy))\n",
        "    else:\n",
        "        raise Exception('Use either l2 or max mode.')\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "def msid_descriptor(x, ts=np.logspace(-1, 1, 256), k=5, m=10, niters=100, rademacher=False, graph_builder='sparse',\n",
        "              normalized_laplacian=True, normalize='empty'):\n",
        "    '''\n",
        "    Compute the msid descriptor for a single sample x\n",
        "    Arguments:\n",
        "        x: x samples\n",
        "        ts: temperature values\n",
        "        k: number of neighbours for graph construction\n",
        "        m: Lanczos steps in SLQ\n",
        "        niters: number of starting random vectors for SLQ\n",
        "        rademacher: if True, sample random vectors from Rademacher distributions, else sample standard normal distribution\n",
        "        graph_builder: if 'kgraph', uses faster graph construction (options: 'sparse', 'kgraph')\n",
        "        normalized_laplacian: if True, use normalized Laplacian\n",
        "        normalize: 'empty' for average heat kernel (corresponds to the empty graph normalization of NetLSD),\n",
        "                'complete' for the complete, 'er' for erdos-renyi\n",
        "                normalization, 'none' for no normalization\n",
        "    Returns:\n",
        "        normed_msidx: normalized msid descriptor\n",
        "    '''\n",
        "    Lx = _build_graph(x, k, graph_builder, normalized_laplacian)\n",
        "\n",
        "    nx = Lx.shape[0]\n",
        "    msidx = slq_red_var(Lx, m, niters, ts, rademacher)\n",
        "\n",
        "    normed_msidx = _normalize_msid(msidx, normalize, nx, k, ts) * NORMALIZATION\n",
        "\n",
        "    return normed_msidx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AklX4WI-qbQG"
      },
      "source": [
        "# **DC Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJEUovshqbQH"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz, ngf = 16, nc = 3):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.nc = nc\n",
        "        self.nz = nz\n",
        "        self.ngf = ngf\n",
        "\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "\n",
        "        self.deconv1 = nn.ConvTranspose2d(self.nz, self.ngf * 16, 4, 2, 1)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(self.ngf*16)\n",
        "        self.deconv2 = nn.ConvTranspose2d(self.ngf * 16,  self.ngf * 8, 4, 2, 1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(self.ngf*8)\n",
        "        self.deconv3 = nn.ConvTranspose2d(self.ngf * 8,  self.ngf * 8, 4, 2, 1)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(self.ngf*8)\n",
        "        self.deconv4 = nn.ConvTranspose2d(self.ngf * 8,  self.ngf * 8, 4, 2, 1)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(self.ngf*8)\n",
        "        self.deconv5 = nn.ConvTranspose2d(self.ngf * 8,  self.ngf * 4, 4, 2, 1)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv6 = nn.ConvTranspose2d(self.ngf * 4,  self.ngf * 4, 4, 2, 1)\n",
        "        self.batchnorm6 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv7 = nn.ConvTranspose2d(self.ngf * 4,  self.ngf * 4, 4, 2, 1)\n",
        "        self.batchnorm7 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv8 = nn.ConvTranspose2d(self.ngf * 4,  self.ngf * 4, 4, 2, 1)\n",
        "        self.batchnorm8 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv9 = nn.ConvTranspose2d(self.ngf * 4,  self.nc,   4, 2, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        input = input.view(len(input), self.nz, 1, 1)\n",
        "\n",
        "        output = self.deconv1(input)\n",
        "        output = self.batchnorm1(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv2(output)\n",
        "        output = self.batchnorm2(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv3(output)\n",
        "        output = self.batchnorm3(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv4(output)\n",
        "        output = self.batchnorm4(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv5(output)\n",
        "        output = self.batchnorm5(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv6(output)\n",
        "        output = self.batchnorm6(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "\n",
        "        output = self.deconv7(output)\n",
        "        output = self.batchnorm7(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv8(output)\n",
        "        output = self.batchnorm8(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv9(output)\n",
        "        output = self.tanh(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def get_name(self):\n",
        "      return 'DC Generator'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnDFf0scqbQH"
      },
      "source": [
        "# **DC Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4y-Kt5yqbQH"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self, d=64):\n",
        "\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, d, 4, 2, 1)\n",
        "        self.conv1_in = nn.BatchNorm2d(d)\n",
        "        self.conv2 = nn.Conv2d(d, d * 2, 4, 2, 1)\n",
        "        self.conv2_in = nn.BatchNorm2d(d * 2)\n",
        "        self.conv3 = nn.Conv2d(d * 2, d * 4, 4, 2, 1)\n",
        "        self.conv3_in = nn.BatchNorm2d(d * 4)\n",
        "        self.conv4 = nn.Conv2d(d * 4, d * 8, 4, 2, 1)\n",
        "        self.conv4_in = nn.BatchNorm2d(d * 8)\n",
        "        self.conv5 = nn.Conv2d(d * 8, 1, 3, 1, 1)\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    # forward method\n",
        "    def forward(self, input):\n",
        "        x = input\n",
        "        x = self.leaky(self.conv1(x))\n",
        "        x = self.leaky(self.conv2_in(self.conv2(x)))\n",
        "        x = self.leaky(self.conv3_in(self.conv3(x)))\n",
        "        x = self.leaky(self.conv4_in(self.conv4(x)))\n",
        "        x = self.conv5(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "        \n",
        "    def get_name(self):\n",
        "      return 'DC Discriminator'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljTKmzDUnh6Y"
      },
      "source": [
        "# **Discriminator with Spectral Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXRhjWOrnlD8"
      },
      "source": [
        "class SNDiscriminator(nn.Module):\n",
        "    def __init__(self,d = 64):\n",
        "        super(SNDiscriminator,self).__init__()\n",
        "\n",
        "        self.conv2d_1 = spectral_norm(nn.Conv2d(3,d,4,2,1))\n",
        "        self.conv2d_2 = spectral_norm(nn.Conv2d(d,d*2, 4,2,1))\n",
        "        self.batchnorm2 = nn.BatchNorm2d(d*2)\n",
        "        self.conv2d_3 = spectral_norm(nn.Conv2d(d*2,d*4, 4,2,1))\n",
        "        self.batchnorm3 = nn.BatchNorm2d(d*4)\n",
        "        self.conv2d_4 = spectral_norm(nn.Conv2d(d*4,d*8, 4,2,1))\n",
        "        self.batchnorm4 = nn.BatchNorm2d(d*8)\n",
        "        self.conv2d_5 = spectral_norm(nn.Conv2d(d*8,d*8,4,2,1))\n",
        "        self.batchnorm5 = nn.BatchNorm2d(d*8)\n",
        "        self.conv2d_6 = spectral_norm(nn.Conv2d(d*8,1,3,1,1))\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "    def forward(self, x):\n",
        "      \n",
        "        x = self.leaky(self.conv2d_1(x))\n",
        "        x = self.leaky(self.batchnorm2(self.conv2d_2(x)))\n",
        "        x = self.leaky(self.batchnorm3(self.conv2d_3(x)))\n",
        "        x = self.leaky(self.batchnorm4(self.conv2d_4(x)))\n",
        "        x = self.leaky(self.batchnorm5(self.conv2d_5(x)))\n",
        "        x = self.sigmoid(self.conv2d_6(x))\n",
        "\n",
        "        return x\n",
        "    def get_name(self):\n",
        "      return 'Spectral Normalization Discriminator'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc8sxFo-jIht"
      },
      "source": [
        "# **Self Attention Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpixqFoyjIh2"
      },
      "source": [
        "class SAGenerator(nn.Module):\n",
        "    def __init__(self, nz, ngf =16, nc = 3):\n",
        "        super(SAGenerator, self).__init__()\n",
        "\n",
        "        self.nc = nc\n",
        "        self.nz = nz\n",
        "        self.ngf = ngf\n",
        "\n",
        "        self.attn1 = Self_Attn(ngf*4,'leakyrelu')\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "        \n",
        "        self.deconv1 = (nn.ConvTranspose2d(self.nz, self.ngf * 16, 4, 2, 1))\n",
        "        self.batchnorm1 = nn.BatchNorm2d(self.ngf*16)\n",
        "        self.deconv2 = (nn.ConvTranspose2d(self.ngf * 16,  self.ngf * 8, 4, 2, 1))\n",
        "        self.batchnorm2 = nn.BatchNorm2d(self.ngf*8)\n",
        "        self.deconv3 = (nn.ConvTranspose2d(self.ngf * 8,  self.ngf * 8, 4, 2, 1))\n",
        "        self.batchnorm3 = nn.BatchNorm2d(self.ngf*8)\n",
        "        self.deconv4 = (nn.ConvTranspose2d(self.ngf * 8,  self.ngf * 8, 4, 2, 1))\n",
        "        self.batchnorm4 = nn.BatchNorm2d(self.ngf*8)\n",
        "        self.deconv5 = (nn.ConvTranspose2d(self.ngf * 8,  self.ngf * 4, 4, 2, 1))\n",
        "        self.batchnorm5 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv6 = (nn.ConvTranspose2d(self.ngf * 4,  self.ngf * 4, 4, 2, 1))\n",
        "        self.batchnorm6 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv7 = (nn.ConvTranspose2d(self.ngf * 4,  self.ngf * 4, 4, 2, 1))\n",
        "        self.batchnorm7 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv8 = (nn.ConvTranspose2d(self.ngf * 4,  self.ngf * 4, 4, 2, 1))\n",
        "        self.batchnorm8 = nn.BatchNorm2d(self.ngf*4)\n",
        "        self.deconv9 = (nn.ConvTranspose2d(self.ngf * 4,  self.nc,   4, 2, 1))\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        input = input.view(len(input), self.nz, 1, 1)\n",
        "\n",
        "        output = self.deconv1(input)\n",
        "        output = self.batchnorm1(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv2(output)\n",
        "        output = self.batchnorm2(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv3(output)\n",
        "        output = self.batchnorm3(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv4(output)\n",
        "        output = self.batchnorm4(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "\n",
        "        output = self.deconv5(output)\n",
        "        output = self.batchnorm5(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output = self.deconv6(output)\n",
        "        output = self.batchnorm6(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "        output,_ = self.attn1(output)\n",
        "\n",
        "        output = self.deconv7(output)\n",
        "        output = self.batchnorm7(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "\n",
        "        output = self.deconv8(output)\n",
        "        output = self.batchnorm8(output)\n",
        "        output = self.leaky(output)\n",
        "\n",
        "\n",
        "        output = self.deconv9(output)\n",
        "        output = self.tanh(output)\n",
        "\n",
        "        return output\n",
        "    \n",
        "    def get_name(self):\n",
        "      return 'Self Attention Generator with Spectral Normalization'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQmk1EhDmepG"
      },
      "source": [
        "# **Critic with Spectral Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8ZMpSdDmepG"
      },
      "source": [
        "class SpectralCritic(nn.Module):\n",
        "    def __init__(self,d = 64):\n",
        "        super(SpectralCritic,self).__init__()\n",
        "\n",
        "        self.conv2d_1 = spectral_norm(nn.Conv2d(3,d,4,2,1))\n",
        "        self.conv2d_2 = spectral_norm(nn.Conv2d(d,d*2, 4,2,1))\n",
        "        self.batchnorm2 = nn.BatchNorm2d(d*2)\n",
        "        self.conv2d_3 = spectral_norm(nn.Conv2d(d*2,d*4, 4,2,1))\n",
        "        self.batchnorm3 = nn.BatchNorm2d(d*4)\n",
        "        self.conv2d_4 = spectral_norm(nn.Conv2d(d*4,d*8, 4,2,1))\n",
        "        self.batchnorm4 = nn.BatchNorm2d(d*8)\n",
        "        self.conv2d_5 = spectral_norm(nn.Conv2d(d*8,d*8,4,2,1))\n",
        "        self.batchnorm5 = nn.BatchNorm2d(d*8)\n",
        "        self.conv2d_6 = spectral_norm(nn.Conv2d(d*8,1,3,1,1))\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "    def forward(self, x):\n",
        "      \n",
        "        x = self.leaky(self.conv2d_1(x))\n",
        "        x = self.leaky(self.batchnorm2(self.conv2d_2(x)))\n",
        "        x = self.leaky(self.batchnorm3(self.conv2d_3(x)))\n",
        "        x = self.leaky(self.batchnorm4(self.conv2d_4(x)))\n",
        "        x = self.leaky(self.batchnorm5(self.conv2d_5(x)))\n",
        "        x = self.conv2d_6(x)\n",
        "\n",
        "        return x\n",
        "    def get_name(self):\n",
        "      return 'Spectral Normalization Critic'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Veo1ixiiOjX"
      },
      "source": [
        "# **Critic**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xkTgtTQiOjX"
      },
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self,d = 64):\n",
        "        super(Critic,self).__init__()\n",
        "\n",
        "        self.conv2d_1 = nn.Conv2d(3,d,4,2,1)\n",
        "        self.conv2d_2 = nn.Conv2d(d,d*2, 4,2,1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(d*2)\n",
        "        self.conv2d_3 = nn.Conv2d(d*2,d*4, 4,2,1)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(d*4)\n",
        "        self.conv2d_4 = nn.Conv2d(d*4,d*8, 4,2,1)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(d*8)\n",
        "        self.conv2d_5 = nn.Conv2d(d*8,d*8,4,2,1)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(d*8)\n",
        "        self.conv2d_6 = nn.Conv2d(d*8,1,3,1,1)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "    def forward(self, x):\n",
        "      \n",
        "        x = self.leaky(self.conv2d_1(x))\n",
        "        x = self.leaky(self.batchnorm2(self.conv2d_2(x)))\n",
        "        x = self.leaky(self.batchnorm3(self.conv2d_3(x)))\n",
        "        x = self.leaky(self.batchnorm4(self.conv2d_4(x)))\n",
        "        x = self.leaky(self.batchnorm5(self.conv2d_5(x)))\n",
        "        x = self.conv2d_6(x)\n",
        "\n",
        "        return x\n",
        "    def get_name(self):\n",
        "      return 'Critic'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9v_Szs9tFpl"
      },
      "source": [
        "# **Loss Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8nA6RfXtIUo"
      },
      "source": [
        "def calculate_disc_loss(loss_type,smooth_labels,cur_batch_size,real,fake,d,fake_prediction_labels,real_prediction_labels,device):\n",
        "  real_label = 0.9\n",
        "  fake_label = 0.1\n",
        "  if loss_type == 'mse':\n",
        "    if smooth_labels:\n",
        "      real_loss = nn.MSELoss()(real_prediction_labels,torch.full(real_prediction_labels.shape, real_label, device=device))\n",
        "      fake_loss = nn.MSELoss()(fake_prediction_labels,torch.full(fake_prediction_labels.shape, fake_label, device=device))\n",
        "    else:\n",
        "      real_loss = nn.MSELoss()(real_prediction_labels,torch.ones_like(real_prediction_labels))\n",
        "      fake_loss = nn.MSELoss()(fake_prediction_labels,torch.zeros_like(fake_prediction_labels))\n",
        "    loss = real_loss + fake_loss\n",
        "\n",
        "  elif loss_type == 'wasserstein':\n",
        "\n",
        "    epsilon = torch.rand(cur_batch_size, 1, 1, 1, device=device, requires_grad=True)\n",
        "    mixed_images = real * epsilon + fake.detach() * (1 - epsilon)\n",
        "    mixed_scores = d(mixed_images)\n",
        "\n",
        "    gradient = torch.autograd.grad(\n",
        "        inputs=mixed_images,\n",
        "        outputs=mixed_scores,\n",
        "        grad_outputs=torch.ones_like(mixed_scores), \n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "    )[0]\n",
        "\n",
        "    gradient_penalty = ((gradient.view(len(gradient), -1).norm(2, dim=1)-1)**2).mean()\n",
        "    loss = torch.mean(fake_prediction_labels) - torch.mean(real_prediction_labels) + 10.0*gradient_penalty\n",
        "  \n",
        "  return loss\n",
        "\n",
        "def calculate_gen_loss(loss_type,smooth_labels, fake_prediction_labels,lambda_weight,fake,real):\n",
        "  real_label = 0.9\n",
        "  if loss_type == 'mse':\n",
        "    if smooth_labels:\n",
        "      loss = nn.MSELoss()(fake_prediction_labels,torch.full(fake_prediction_labels.shape, real_label, device=device)) + lambda_weight*nn.L1Loss()(fake,real)\n",
        "    else:\n",
        "      loss = nn.MSELoss()(fake_prediction_labels,torch.ones_like(fake_prediction_labels)) + lambda_weight*nn.L1Loss()(fake,real)\n",
        "\n",
        "  elif loss_type == 'wasserstein':\n",
        "    loss = -torch.mean(fake_prediction_labels) + lambda_weight*nn.L1Loss()(fake,real)\n",
        " \n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Dp4ClpAAnJv"
      },
      "source": [
        "# **Train GAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNAkbTip4-eV"
      },
      "source": [
        "def train_gan(generator, discriminator, data, dir, imgs_path, loss, n_epochs, disc_lr, gen_lr, z_dim, lambda_weight , smooth_labels):\n",
        "  generator.to(device)\n",
        "  discriminator.to(device)\n",
        "\n",
        "  init_weights(generator)\n",
        "  init_weights(discriminator)\n",
        "  \n",
        "  n_batches = len(data)\n",
        "  num_of_params_g = sum(p.numel() for p in generator.parameters() if p.requires_grad)\n",
        "  num_of_params_d = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)\n",
        "\n",
        "  num_of_params = num_of_params_d+num_of_params_g\n",
        "\n",
        "  print('Shape of the generated image: ({},{})'.format(512,512))\n",
        "\n",
        "  gen_opt = torch.optim.AdamW(generator.parameters(),lr=gen_lr,betas =(0.5,0.99))\n",
        "  disc_opt = torch.optim.AdamW(discriminator.parameters(),lr=disc_lr,betas =(0.5,0.99))\n",
        "  g_scheduler = MultiStepLR(gen_opt,milestones = [100,200])\n",
        "  d_scheduler = MultiStepLR(disc_opt,milestones = [100,200]) \n",
        "\n",
        "  loss_dict = {'Epoch': [],\n",
        "              'Generator Loss': [],\n",
        "              'Discriminator Loss': [],\n",
        "              }\n",
        "\n",
        "\n",
        "  param_dict = {'Generator': [generator.get_name()],\n",
        "                'Discriminator': [discriminator.get_name()],\n",
        "                'Batch Size': [data.batch_size],\n",
        "                'Noise Dimension': [z_dim],\n",
        "                'Loss Function': [loss],\n",
        "                'Label Smoothing': [smooth_labels],\n",
        "                'L1 weight': [lambda_weight],\n",
        "                'Generator Learning Rate': [gen_lr],\n",
        "                'Disriminator Learning Rate': [disc_lr],\n",
        "                'Training Time': [0],\n",
        "                'Model Parameters': [num_of_params]\n",
        "                  }\n",
        "  \n",
        "  check_or_create_dir(0, dir)\n",
        "\n",
        "  training_start = time.time()\n",
        "  for epoch in range(n_epochs):\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "    #Initialize losses\n",
        "    g_loss = 0\n",
        "    d_loss = 0\n",
        "    for real in tqdm(data):\n",
        "      real = real.float().to(device)\n",
        "      cur_batch_size = len(real)\n",
        "      #Discriminator\n",
        "      disc_opt.zero_grad()\n",
        "      real_data= 0.9*real+0.1*torch.randn((real.size()), device=device)\n",
        "      real_prediction_labels = discriminator(real_data)\n",
        "      noise = get_noise(cur_batch_size, z_dim,device)\n",
        "      fake_generated = generator(noise)\n",
        "      fake_data = 0.9*fake_generated.detach()+0.1*torch.randn((fake_generated.size()), device=device)\n",
        "      fake_prediction_labels = discriminator(fake_data.detach())\n",
        "      disc_loss = calculate_disc_loss(loss,smooth_labels,cur_batch_size,real,fake_generated,discriminator,fake_prediction_labels,real_prediction_labels,device)\n",
        "      disc_loss.backward()\n",
        "      disc_opt.step()\n",
        "      d_scheduler.step()\n",
        "\n",
        "      ####Generator####\n",
        "      gen_opt.zero_grad()\n",
        "      fake_generated = generator(get_noise(cur_batch_size, z_dim,device))\n",
        "      fake_data = 0.9*fake_generated+0.1*torch.randn((fake_generated.size()), device=device)\n",
        "      fake_prediction_labels = discriminator(fake_data)\n",
        "      gen_loss = calculate_gen_loss(loss,smooth_labels,fake_prediction_labels,lambda_weight,fake_generated,real)\n",
        "      gen_loss.backward()\n",
        "      gen_opt.step()\n",
        "      g_scheduler.step()\n",
        "\n",
        "      g_loss += gen_loss\n",
        "      d_loss += disc_loss\n",
        "\n",
        "    g_loss = g_loss/n_batches\n",
        "    d_loss = d_loss/n_batches\n",
        "\n",
        "    loss_dict['Epoch'].append(epoch) \n",
        "    loss_dict['Generator Loss'].append(g_loss.item()) \n",
        "    loss_dict['Discriminator Loss'].append(d_loss.item())\n",
        "\n",
        "    print(f\"Epoch: {epoch} Gen Loss: {g_loss.item()} Disc Loss: {d_loss.item()}\")\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "\n",
        "\n",
        "    ####Save the Generator model/parameters/generated images####\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      torch.save(generator., os.path.join(dir,f'generator_{epoch}.pth'))\n",
        "      torch.save(discriminator,os.path.join(dir,f'discriminator_{epoch}.pth'))\n",
        "      plot(loss,epoch,loss_dict['Generator Loss'],loss_dict['Discriminator Loss'],dir)\n",
        "      show_images(real)\n",
        "      show_images(fake_generated)\n",
        "    save_gen_images(dir, imgs_path, device, epoch, z_dim, generator, num_images=25, size=(3, 512, 512))\n",
        "\n",
        "  training_stop = time.time()\n",
        "  param_dict['Training Time'] = (training_stop-training_start)\n",
        "  losses_pd = pd.DataFrame.from_dict(loss_dict) \n",
        "  losses_pd.to_csv(os.path.join(dir,'losses_history.csv'))\n",
        "  param_pd = pd.DataFrame.from_dict(param_dict)\n",
        "  param_pd.to_csv(os.path.join(dir,'parameters.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Df0G4ZFAeoH"
      },
      "source": [
        "# **Train WGAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPa4viGs_w_r"
      },
      "source": [
        "def train_wgan(generator, discriminator, data,all_data, dir, imgs_path, loss, n_epochs, disc_lr, gen_lr, z_dim, lambda_weight , smooth_labels,d_repeats):\n",
        "  init_weights(generator)\n",
        "  init_weights(discriminator)\n",
        "  \n",
        "  model = GAN(generator,discriminator).to(device)\n",
        "  num_of_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  print('Shape of the generated image: ({},{})'.format(512,512))\n",
        "  n_batches = len(data)\n",
        "\n",
        "  gen_lr  = 0.00005\n",
        "  disc_lr = 0.00005\n",
        "\n",
        "  gen_opt = torch.optim.RMSprop(model.gen.parameters(),lr=gen_lr)\n",
        "  disc_opt = torch.optim.RMSprop(model.disc.parameters(),lr=disc_lr)\n",
        "  g_scheduler = MultiStepLR(gen_opt,milestones = [100,199])\n",
        "  d_scheduler = MultiStepLR(disc_opt,milestones = [100,199])\n",
        "\n",
        "  loss_dict = {'Epoch': [],\n",
        "              'Generator Loss': [],\n",
        "              'Discriminator Loss': [],\n",
        "              }\n",
        "\n",
        "  param_dict = {'Generator': [model.gen.get_name()],\n",
        "                'Discriminator': [model.disc.get_name()],\n",
        "                'Discriminator Repeats': [d_repeats],\n",
        "                'Batch Size': [all_imgs_dataloader.batch_size],\n",
        "                'Noise Dimension': [z_dim],\n",
        "                'Loss Function': [loss_type],\n",
        "                'Label Smoothing': [smooth_labels],\n",
        "                'L1 weight': [lambda_weight],\n",
        "                'Generator Learning Rate': [gen_lr],\n",
        "                'Disriminator Learning Rate': [disc_lr],\n",
        "                'Training Time': [0],\n",
        "                'Model Parameters': [num_of_params]\n",
        "                  }\n",
        "\n",
        "  check_or_create_dir(0, dir)\n",
        "\n",
        "\n",
        "  \n",
        "  training_start = time.time()\n",
        "  for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    g_loss = 0\n",
        "    d_loss = 0\n",
        "    for real in tqdm(data):\n",
        "      real = real.float().to(device)\n",
        "      cur_batch_size = len(real)\n",
        "      #Discriminator\n",
        "      loss_disc_iter = 0\n",
        "      for repeat in range(d_repeats):\n",
        "        disc_opt.zero_grad()\n",
        "        real_data= 0.9*real+0.1*torch.randn((real.size()), device=device)\n",
        "        real_prediction_labels = model.disc(real_data)\n",
        "        noise = get_noise(cur_batch_size, z_dim,device)\n",
        "        fake_generated = model.gen(noise)\n",
        "        fake_data = 0.9*fake_generated.detach()+0.1*torch.randn((fake_generated.size()), device=device)\n",
        "        fake_prediction_labels = model.disc(fake_data.detach())\n",
        "        disc_loss = calculate_disc_loss(loss,smooth_labels,cur_batch_size,real,fake_generated,model.disc,fake_prediction_labels,real_prediction_labels,device)\n",
        "        disc_loss.backward()\n",
        "        disc_opt.step()\n",
        "        d_scheduler.step()\n",
        "        loss_disc_iter += disc_loss/d_repeats\n",
        "      disc_loss = loss_disc_iter\n",
        "\n",
        "      ####Generator####\n",
        "      gen_opt.zero_grad()\n",
        "      fake_generated = model.gen(get_noise(cur_batch_size, z_dim,device))\n",
        "      fake_data = 0.9*fake_generated+0.1*torch.randn((fake_generated.size()), device=device)\n",
        "      fake_prediction_labels = model.disc(fake_data)\n",
        "      gen_loss = calculate_gen_loss(loss,smooth_labels,fake_prediction_labels,lambda_weight,fake_generated,real)\n",
        "      gen_loss.backward()\n",
        "      gen_opt.step()\n",
        "      g_scheduler.step()\n",
        "\n",
        "      g_loss += gen_loss\n",
        "      d_loss += disc_loss\n",
        "\n",
        "    g_loss = g_loss/n_batches\n",
        "    d_loss = d_loss/n_batches\n",
        "\n",
        "    loss_dict['Epoch'].append(epoch) \n",
        "    loss_dict['Generator Loss'].append(g_loss.item()) \n",
        "    loss_dict['Discriminator Loss'].append(d_loss.item())\n",
        "\n",
        "    print(f\"Epoch: {epoch} Gen Loss: {g_loss.item()} Disc Loss: {d_loss.item()}\")\n",
        "\n",
        "    ####Save the Generator model/parameters/generated images####\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      plot(loss_type,epoch,loss_dict['Generator Loss'],loss_dict['Discriminator Loss'],dir)\n",
        "      torch.save(model.gen, os.path.join(dir,f'generator_{epoch}.pth'))\n",
        "      torch.save(model.disc,os.path.join(dir,f'discriminator_{epoch}.pth'))\n",
        "      plot(loss,epoch,loss_dict['Generator Loss'],loss_dict['Discriminator Loss'],dir)\n",
        "      show_images(real)\n",
        "      show_images(fake_generated)\n",
        "    save_gen_images(dir, imgs_path, device, epoch, z_dim, model.gen, num_images=25, size=(3, 512, 512))\n",
        "\n",
        "  training_stop = time.time()\n",
        "  param_dict['Training Time'][0] = (training_stop-training_start) \n",
        "  losses_pd = pd.DataFrame.from_dict(loss_dict)\n",
        "  losses_pd.to_csv(os.path.join(dir,'losses_history.csv'))\n",
        "  param_pd = pd.DataFrame.from_dict(param_dict)\n",
        "  param_pd.to_csv(os.path.join(dir,'parameters.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mkx2QY5u-gf"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe2rEaqKZLvg"
      },
      "source": [
        "generator = SAGenerator(128)\n",
        "discriminator = Discriminator()\n",
        "\n",
        "data = all_imgs_dataloader_batch_1\n",
        "dir = '/content/drive/MyDrive/Thesis_Material/SAGAN'\n",
        "imgs_path = os.path.join(dir,'Generated_Images')\n",
        "\n",
        "\n",
        "n_epochs = 200\n",
        "disc_lr = 0.001\n",
        "gen_lr = 0.0002\n",
        "z_dim = 128\n",
        "lambda_weight = 2.0\n",
        "smooth_labels=True\n",
        "gan ='gan'\n",
        "loss_type ='mse'\n",
        "\n",
        "if gan == 'gan':\n",
        "  train_gan(generator, discriminator, data, dir, imgs_path, 'mse', n_epochs, disc_lr, gen_lr, z_dim, lambda_weight , smooth_labels)\n",
        "elif gan == 'wgan':\n",
        "  train_wgan(generator, discriminator, data,all_data, dir, imgs_path, 'wasserstein', n_epochs, disc_lr, gen_lr, z_dim, lambda_weight , smooth_labels,d_repeats = 2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb_gXd3OOCSl"
      },
      "source": [
        "# **Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA6nZKKG1Kgw"
      },
      "source": [
        "#Create an array with all the real images to be used in IMD calculation\n",
        "\n",
        "def from_path_to_numpy(path):\n",
        "  images_list = os.listdir(path)\n",
        "  images_list.sort()\n",
        "  len_dataset = len(images_list)\n",
        "  dataset = np.zeros([len_dataset, 512, 512, 3])\n",
        "  for i in range(len_dataset):\n",
        "      dataset[i] = cv2.resize(cv2.imread(os.path.join(path, images_list[i])), (512, 512))\n",
        "  return dataset\n",
        "\n",
        "real_dir = '/content/drive/MyDrive/sim2real_dataset/sim2real_dataset/backgrounds'\n",
        "test_dir = '/content/drive/My Drive/Thesis_Material'\n",
        "\n",
        "real_dataset = from_path_to_numpy(real_dir)\n",
        "real_dataset = real_dataset.reshape(105,-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAfPiqrX4sfw"
      },
      "source": [
        "real_dir = '/content/drive/MyDrive/sim2real_dataset/sim2real_dataset/backgrounds'\n",
        "test_dir = '/content/drive/My Drive/Thesis_Material'\n",
        "model_list = ['WGAN_64_xavier USED','SNWGAN_64_xavier USED']\n",
        "\n",
        "for model in model_list:\n",
        "\n",
        "  inception_scores = {'Epoch': [],\n",
        "                      'IS': [],\n",
        "                      'IS std': []}\n",
        "\n",
        "  fid_scores = {'Epoch':[],\n",
        "              'FID Score': []}\n",
        "\n",
        "  imd_scores = {'Epoch':[],\n",
        "              'IMD Score': []}\n",
        "\n",
        "\n",
        "  model_dir = os.path.join('/content/drive/My Drive/Thesis_Material',model)\n",
        "  for step in range(0,201,10):\n",
        "    gen = torch.load(os.path.join(model_dir,f'generator_{step}.pth')).to(device)\n",
        "    gen.eval()\n",
        "    fake_path = os.path.join(model_dir,f'fakes_at_step_{step}')\n",
        "    check_or_create_dir(0,fake_path)  \n",
        "    for i in range(105):\n",
        "      img = gen(get_noise(1,128,device)).squeeze(0).permute(1,2,0).detach().cpu().numpy()\n",
        "      im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      cv2.imwrite(os.path.join(fake_path,f'fake_img{i}.jpg'), 255*im_rgb)\n",
        "\n",
        "  print(f'Calculating Evaluation Metrics for {model} ...')\n",
        "\n",
        "  for step in range(0,201,10):\n",
        "    fid = calculate_FID_score(real_dir, os.path.join(model_dir,f'fakes_at_step_{step}'))\n",
        "    fid_scores['Epoch'].append(step)\n",
        "    fid_scores['FID Score'].append(fid)\n",
        "\n",
        "    IS, IS_std = get_inception_score_from_directory(os.path.join(model_dir,f'fakes_at_step_{step}'))\n",
        "    inception_scores['Epoch'].append(step)\n",
        "    inception_scores['IS'].append(IS)\n",
        "    inception_scores['IS std'].append(IS_std)\n",
        "\n",
        "    fake_dataset = from_path_to_numpy(os.path.join(model_dir,f'fakes_at_step_{step}'))\n",
        "    fake_dataset = fake_dataset.reshape(105,-1)\n",
        "    imd = msid_score(real_dataset,fake_dataset)\n",
        "\n",
        "    imd_scores['Epoch'].append(step)\n",
        "    imd_scores['IMD Score'].append(imd)\n",
        "\n",
        "    print(f'At epoch {step}: FID: {fid} IMD: {imd}')\n",
        "\n",
        "  fid_pd = pd.DataFrame.from_dict(fid_scores)\n",
        "  fid_pd.to_csv(os.path.join(model_dir,'fid_scores.csv'))\n",
        "\n",
        "  imd_pd = pd.DataFrame.from_dict(imd_scores)\n",
        "  imd_pd.to_csv(os.path.join(model_dir,'imd_scores.csv'))\n",
        "\n",
        "  is_pd = pd.DataFrame.from_dict(inception_scores)\n",
        "  is_pd.to_csv(os.path.join(model_dir,'inception_scores.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMv-h6mdiOxP"
      },
      "source": [
        "gan_model_list = ['DCGAN','SNGAN','SAGAN+SN','WGAN+SN','WGAN-GP','WGAN']\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "for model in gan_model_list:\n",
        "  model_dir = os.path.join('/content/drive/My Drive/Thesis_Material',model)\n",
        "  losses = pd.read_csv(os.path.join(model_dir,'imd_scores.csv'))\n",
        "  ax1.plot(np.arange(0,201,10),losses['IMD Score'],label = model)\n",
        "  ax1.legend()\n",
        "  ax1.set_title('IMD for GAN architectures')\n",
        "  ax1.set_xlabel('Epoch')\n",
        "  ax1.set_ylabel('IMD')\n",
        "plt.savefig('/content/drive/My Drive/Thesis_Material/imd_gan_plot.png')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}